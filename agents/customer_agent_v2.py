# -*- coding: utf-8 -*-
"""
@file: customer_agent.py
@desc: å¤„ç†TikTokè¯„è®ºçš„ä»£ç†ç±»ï¼Œæä¾›è¯„è®ºè·å–ã€åˆ†æå’Œæ½œåœ¨å®¢æˆ·è¯†åˆ«åŠŸèƒ½
@auth: Callmeiks
"""

import json
import re
from datetime import datetime
from typing import Dict, Any, List, Optional, Union
import asyncio
import time

import numpy as np
import pandas as pd
from dotenv import load_dotenv
import os

from app.config import settings
from app.utils.logger import setup_logger
from services.ai_models.chatgpt import ChatGPT
from services.ai_models.claude import Claude
from services.cleaner.comment_cleaner import CommentCleaner
from services.cleaner.video_cleaner import VideoCleaner
from services.crawler.comment_crawler import CommentCollector
from app.core.exceptions import ValidationError, ExternalAPIError, InternalServerError
from services.crawler.video_crawler import VideoCollector

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = setup_logger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class CustomerAgent:
    """å¤„ç†TikTokè¯„è®ºçš„ä»£ç†ç±»ï¼Œæä¾›è¯„è®ºè·å–ã€åˆ†æå’Œæ½œåœ¨å®¢æˆ·è¯†åˆ«åŠŸèƒ½"""

    def __init__(self, tikhub_api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–CustomerAgentï¼ŒåŠ è½½APIå¯†é’¥å’Œæç¤ºæ¨¡æ¿

        Args:
            tikhub_api_key: TikHub APIå¯†é’¥
            tikhub_base_url: TikHub APIåŸºç¡€URL
        """

        self.customer_count = 0
        # åˆå§‹åŒ–AIæ¨¡å‹å®¢æˆ·ç«¯
        self.chatgpt = ChatGPT()
        self.claude = Claude()

        self.comment_collector = CommentCollector(tikhub_api_key, settings.TIKHUB_BASE_URL)
        self.comment_cleaner = CommentCleaner()

        # ä¿å­˜TikHub APIé…ç½®
        self.tikhub_api_key = tikhub_api_key
        self.tikhub_base_url = settings.TIKHUB_BASE_URL

        # å¦‚æœæ²¡æœ‰æä¾›TikHub APIå¯†é’¥ï¼Œè®°å½•è­¦å‘Š
        if not self.tikhub_api_key:
            logger.warning("æœªæä¾›TikHub APIå¯†é’¥ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

        # æ”¯æŒçš„åˆ†æç±»å‹åˆ—è¡¨
        self.analysis_types = ['purchase_intent']

        # åŠ è½½ç³»ç»Ÿå’Œç”¨æˆ·æç¤º
        self._load_system_prompts()
        self._load_user_prompts()

    def _load_system_prompts(self) -> None:
        """åŠ è½½ç³»ç»Ÿæç¤ºç”¨äºä¸åŒçš„è¯„è®ºåˆ†æç±»å‹"""
        self.system_prompts = {
            'purchase_intent': """You are an AI trained to analyze social media comments about products.
            For each comment in the provided list, analyze:
            1. Sentiment (positive, negative, or neutral)
            2. Purchase Intent (whether the user shows any interest in buying, trying, or acquiring the product)
            3. User Interest Level (high, medium, low)

            For each comment, provide analysis in the following JSON format:
            {
                "comment_id": "comment ID from input data",
                "text": "comment text",
                "sentiment": "positive/negative/neutral",
                "purchase_intent": true/false,
                "interest_level": "high/medium/low",
            }

            Respond with a JSON array containing analysis for all comments.
            Focus on identifying any signs of interest in the product, including:
            - Direct purchase intentions ("want to buy", "need this")
            - Indirect interest ("where can I find this", "love this")
            - Questions about product details
            - emojis indicating positive sentiment or interest
            - Positive reactions to product features
            - Any positive sentiment to the influencer herself/himself is consider neutral
            - Any engagement indicating potential future purchase""",
            'customer_reply': """# # Multilingual Customer Service AI Assistant

            ## System Instruction

            You are an advanced multilingual customer service AI for an e-commerce platform. Your task is to:
            1. Analyze the store information provided by the merchant
            2. Identify the language of both the store information and customer message
            3. Generate a helpful, accurate response to the customer inquiry
            4. Return your response in a structured JSON format

            ## Analysis Guidelines

            1. **Language Detection**:
               - Automatically detect the language of the store information
               - Automatically detect the language of the customer message
               - Translate the customer message to the store language
               - Determine the most appropriate language for your response (typically matching the customer's language)

            2. **Store Information Analysis**:
               - Extract key details about products, pricing, shipping, returns, promotions, etc.
               - Understand store policies across different languages
               - Identify store name and branding elements

            3. **Customer Message Analysis**:
               - Identify the customer's primary question or concern
               - Detect any secondary questions
               - Understand the customer's tone and respond appropriately

            ## Response Generation

            1. **Content Creation**:
               - Provide accurate information based only on the store details provided
               - If information is not available, acknowledge this limitation politely
               - Structure your response with greeting, answer, additional information.
               - Be concise and to the point, avoiding unnecessary details, usually one or two sentences is enough.
               - Maintain a helpful, professional tone appropriate to the detected culture
               - Also generate a translated version of your response in the shop language

            2. **Response Language**:
               - Respond in the same language as the customer message
               - If you cannot confidently respond in the customer's language, default to the store's language
               - Use culturally appropriate greetings and expressions

            ## JSON Output Format

            Your response must be formatted as a valid JSON object with the following structure:
            ```json
            {
              "detected_store_language": "language_code",
              "detected_customer_language": "language_code",
              "response_language": "language_code",
              'translated_customer_message': 'translated message',
              "response_text": "Your complete customer service response",
              "response_text_translated": "Your response translated to the store language",
              "confidence_score": 0.95
            }
            """,
            'batch_customer_reply': """## Multilingual Batch Customer Service AI Assistant
### System Instruction
You are an advanced multilingual customer service AI for an e-commerce platform. Your task is to process multiple customer messages simultaneously and generate appropriate responses for each.
### Input Format
You will receive a JSON object with the following structure:
```json
{
  "shop_info": "Complete store information in any language",
  "messages": [
    {
      "message_id": 0,
      "commenter_uniqueId": "customer_unique_id_1",
      "comment_id": "optional_comment_id_1",
      "message_text": "Customer message 1 in any language"
    },
    {
      "message_id": 1,
      "commenter_uniqueId": "customer_unique_id_2",
      "comment_id": "optional_comment_id_2",
      "message_text": "Customer message 2 in any language"
    },
    ...
  ]
}
```
### Processing Steps
For each customer message, perform the following:

#### 1. Language Detection
- Detect the language of the store information.
- Detect the language of the customer message.
- Choose the appropriate language for your response (typically the customer's language).

#### 2. Message Translation
- If the customer's language differs from the store language, translate the customer message TO THE STORE'S LANGUAGE and save it as translated_customer_message.
- This translation helps the store owner understand what the customer is saying in the store owner's language.

#### 3. Content Analysis
- Understand the store policies, products, and services based on the `shop_info`.
- Identify the customer's question or concern.
- Formulate a helpful, accurate response based only on the available information.

#### 4. Response Creation
Generate a complete, professional response in the customer's language. Include:
- **Greeting:** Friendly opening appropriate to the language/culture.
- **Answer:** Directly address the customer's question.

If necessary, translate your response into the store's language for reference.

### Output Format
Return a JSON array containing one object for each input message in the same order as received. Each object must have the following structure:

```json
[
  {
    "message_id": 0,
    "detected_store_language": "language_code",
    "detected_customer_language": "language_code",
    'customer_unique_id': 'customer_unique_id_1',
    "translated_customer_message": "translated message",
    "response_text": "Your complete customer service response in customer's language",
    "response_text_translated": "Your response translated to the store language"
  },
  {
    "message_id": 1,
    "detected_store_language": "language_code",
    "detected_customer_language": "language_code",
    'customer_unique_id': 'customer_unique_id_2',
    "translated_customer_message": "translated message",
    "response_text": "Your complete customer service response in customer's language",
    "response_text_translated": "Your response translated to the store language"
  }
]
```

### Important Rules
âœ… Return **ONLY** a valid JSON array with objects matching the format above.
âœ… Use **ISO 639-1** codes for language identification (e.g., "en", "zh", "fr", "es").
âœ… Base responses **ONLY** on the provided store information.
âœ… If the provided information is insufficient to answer a question, clearly state this.
âœ… Maintain a professional and helpful tone.

### Response Content Guidelines
Each response should include:
- **Greeting** - Friendly and culturally appropriate.
- **Answer** - Direct and accurate, usually one or two sentences is enough.

This format ensures efficient multilingual customer support while maintaining high-quality, contextually relevant responses. ğŸš€
"""
        }

    def _load_user_prompts(self) -> None:
        """åŠ è½½ç”¨æˆ·æç¤ºç”¨äºä¸åŒçš„è¯„è®ºåˆ†æç±»å‹"""
        self.user_prompts = {
            'purchase_intent': {
                'description': 'purchase intent'
            }
        }

    async def fetch_video_comments(self, aweme_id: str, ins_filter: bool = False, twitter_filter: bool = False, region_filter: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šè§†é¢‘çš„æ¸…ç†åçš„è¯„è®ºæ•°æ®

        Args:
            aweme_id (str): è§†é¢‘ID
            ins_filter (bool): æ˜¯å¦è¿‡æ»¤Instagramä¸ºNoneçš„è¯„è®º
            twitter_filter (bool): æ˜¯å¦è¿‡æ»¤Twitterä¸ºNoneçš„è¯„è®º
            region_filter (str): è¯„è®ºåŒºåŸŸè¿‡æ»¤å™¨ï¼Œä¾‹å¦‚"US"ï¼Œ"GB"ç­‰

        Returns:
            Dict[str, Any]: æ¸…ç†åçš„è¯„è®ºæ•°æ®ï¼ŒåŒ…å«è§†é¢‘IDå’Œè¯„è®ºåˆ—è¡¨

        Raises:
            ValidationError: å½“aweme_idä¸ºç©ºæˆ–æ— æ•ˆæ—¶
            ExternalAPIError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
        """
        start_time = time.time()

        try:
            if not aweme_id or not isinstance(aweme_id, str):
                raise ValidationError(detail="aweme_idå¿…é¡»æ˜¯æœ‰æ•ˆçš„å­—ç¬¦ä¸²", field="aweme_id")

            # è®°å½•å¼€å§‹è·å–è¯„è®º
            logger.info(f"ğŸ” å¼€å§‹è·å–è§†é¢‘ {aweme_id} çš„è¯„è®º")

            # è·å–è¯„è®º
            comments = await self.comment_collector.collect_video_comments(aweme_id)

            if not comments or not comments.get('comments'):
                logger.warning(f"âŒ è§†é¢‘ {aweme_id} æœªæ‰¾åˆ°è¯„è®º")
                return {
                    'aweme_id': aweme_id,
                    'comments': [],
                    'comment_count': 0,
                    'timestamp': datetime.now().isoformat()
                }

            # æ¸…æ´—è¯„è®º
            cleaned_comments = await self.comment_cleaner.clean_video_comments(comments)
            cleaned_comments = cleaned_comments.get('comments', [])

            comments_df = pd.DataFrame(cleaned_comments)

            # è¿‡æ»¤æ¡ä»¶
            if ins_filter:
                comments_df = comments_df[comments_df['ins_id']!= '']
            if twitter_filter:
                comments_df = comments_df[comments_df['twitter_id']!= '']
            if region_filter:
                comments_df = comments_df[comments_df['commenter_region'] == region_filter]

            processing_time = time.time() - start_time

            result = {
                'aweme_id': aweme_id,
                'comments': comments_df.to_dict(orient='records'),
                'comment_count': len(comments_df),
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round(processing_time * 1000, 2)
            }

            logger.info(f"æˆåŠŸè·å–è§†é¢‘ {aweme_id} çš„è¯„è®º: {len(comments_df)} æ¡ï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return result

        except (ValidationError, ExternalAPIError) as e:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿™äº›å·²å¤„ç†çš„é”™è¯¯
            logger.error(f"è·å–è§†é¢‘è¯„è®ºæ—¶å‡ºé”™: {str(e)}")
            raise e
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘è¯„è®ºæ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            raise InternalServerError(detail=f"è·å–è§†é¢‘è¯„è®ºæ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")

    async def get_potential_customers(
            self,
            aweme_id: str,
            batch_size: int = 30,
            max_count: int = 100,
            concurrency: int = 5,
            min_score: float = 50.0,
            max_score: float = 100.0,
            ins_filter: bool = False,
            twitter_filter: bool = False,
            region_filter: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        è·å–æ½œåœ¨å®¢æˆ·åˆ—è¡¨

        1. è°ƒç”¨fetch_video_commentsæ–¹æ³•è·å–è§†é¢‘è¯„è®º
        2. ä½¿ç”¨ins_filterï¼Œtwitter_filter, region_filter å»è¿‡æ»¤æ•°æ®
        3. ä½¿ç”¨AIæ¨¡å‹åˆ†æç¬¦åˆæ¡ä»¶è¯„è®ºï¼Œè¯†åˆ«æ½œåœ¨å®¢æˆ·
        4. è¿”å›æ½œåœ¨å®¢æˆ·åˆ—è¡¨
        """


        start_time = time.time()
        potential_customers = []  # æ½œåœ¨å®¢æˆ·åˆ—è¡¨

        try:
            # è·å–è¯„è®ºæ•°æ®ï¼Œå¹¶ä¸”è¿‡æ»¤+æ¸…æ´—
            comments_data = await self.fetch_video_comments(aweme_id, ins_filter, twitter_filter, region_filter)
            comments = comments_data.get('comments')

            # å°†commentsåˆ—è¡¨è½¬æ¢ä¸ºDataFrame
            comments_df = pd.DataFrame(comments)

            # å°†æ¸…æ´—åçš„è¯„è®ºæ•°æ®æŒ‰ç…§AIå¹¶å‘é‡ï¼ˆconcurrencyï¼‰åˆ†æ‰¹å¤„ç†
            num_splits = max(1, len(comments_df) // batch_size + (1 if len(comments_df) % batch_size > 0 else 0))
            comment_batches = np.array_split(comments_df, num_splits)
            logger.info(
                f"ğŸš€ å¼€å§‹åˆ†æè¯„è®ºï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {len(comment_batches[0]) if len(comment_batches) > 0 else 0} æ¡è¯„è®º"
            )

            # æŒ‰ç…§æ‰¹æ¬¡å¤„ç†è¯„è®º
            for i in range(0, len(comment_batches), concurrency):
                batch_group = comment_batches[i:i + concurrency]
                batch_indices = [
                    f"{batch.index[0]}-{batch.index[-1]}" if not batch.empty else "-"
                    for batch in batch_group
                ]
                logger.info(
                    f"âš¡ å¤„ç†æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}"
                )

                # å¼€å§‹ä½¿ç”¨AIæ¨¡å‹åˆ†æè¯„è®º
                tasks = [
                    self._analyze_aspect('purchase_intent', batch[['text', 'comment_id']].to_dict('records'))
                    for batch in batch_group if not batch.empty
                ]
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)

                # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡çš„ç»“æœ
                for j, (batch, result) in enumerate(zip(batch_group, batch_results)):
                    if isinstance(result, Exception) or not result:  # å¦‚æœç»“æœä¸ºç©ºæˆ–è€…æ˜¯å¼‚å¸¸
                        logger.error(f"æ‰¹æ¬¡ {i + j + 1} åˆ†æå¤±è´¥: {str(result)}")
                    else:
                        result_df = pd.DataFrame(result)
                        if not result_df.empty and 'comment_id' in result_df.columns:  # å¦‚æœç»“æœä¸ä¸ºç©º, å¹¶ä¸”åŒ…å«comment_id
                            # åˆå¹¶åˆ†æç»“æœåˆ°åŸå§‹è¯„è®º
                            merged_batch = pd.merge(
                                batch,
                                result_df,
                                on='comment_id',
                                how='left',
                                suffixes=('', '_analysis')
                            )

                            # è®¡ç®—å‚ä¸åº¦åˆ†æ•°
                            merged_batch['engagement_score'] = merged_batch.apply(
                                lambda row: self._calculate_engagement_score(
                                    row['sentiment'],
                                    row['purchase_intent'],
                                    row['interest_level']
                                ),
                                axis=1
                            )

                            # è¿‡æ»¤åˆ†æ•°åœ¨min_scoreå’Œmax_scoreä¹‹é—´çš„è¯„è®º
                            filtered_batch = merged_batch[
                                (merged_batch['engagement_score'] >= min_score) &
                                (merged_batch['engagement_score'] <= max_score)
                                ]

                            # è®°å½•æ½œåœ¨å®¢æˆ·æ•°é‡
                            self.customer_count += len(filtered_batch)
                            logger.info(f"æ‰¹æ¬¡ {i + j + 1} å¤„ç†å®Œæˆ: åŸå§‹è¯„è®º {len(batch)}ï¼Œ"
                                        f"åˆ†æå {len(merged_batch)}ï¼Œè¿‡æ»¤å {len(filtered_batch)}")

                            # å¦‚æœå®¢æˆ·æ€»æ•°è¶…è¿‡æœ€å¤§é™åˆ¶ï¼Œåˆ™åªæ·»åŠ åˆ°æœ€å¤§é™åˆ¶
                            if self.customer_count > max_count:
                                potential_customers.extend(
                                    filtered_batch.head(max_count - self.customer_count).to_dict('records'))
                                self.comment_collector.status = False  # åœæ­¢æ”¶é›†è¯„è®º
                                self.comment_cleaner.status = False  # åœæ­¢æ¸…æ´—è¯„è®º
                                logger.info(
                                    f"ç°åœ¨å·²ç»æœ‰ {self.customer_count} ä¸ªæ½œåœ¨å®¢æˆ·ï¼Œè¾¾åˆ°æœ€å¤§é™åˆ¶ {max_count}ï¼Œåœæ­¢å¤„ç†")
                                break

                            # æ·»åŠ åˆ°æ½œåœ¨å®¢æˆ·åˆ—è¡¨
                            potential_customers.extend(filtered_batch.to_dict('records'))
                        else:
                            logger.warning(f"æ‰¹æ¬¡ {i + j + 1} åˆ†æç»“æœæ ¼å¼æ— æ•ˆæˆ–ä¸ºç©º")
                            # ä¿ç•™åŸå§‹æ‰¹æ¬¡
                            potential_customers = batch.to_dict('records')

                # å¦‚æœå®¢æˆ·æ€»æ•°è¶…è¿‡æœ€å¤§é™åˆ¶ï¼Œåˆ™åœæ­¢å¤„ç†
                if self.customer_count > max_count:
                    self.comment_collector.status = False  # åœæ­¢æ”¶é›†è¯„è®º
                    self.comment_cleaner.status = False  # åœæ­¢æ¸…æ´—è¯„è®º
                    break

            processing_time = time.time() - start_time
            logger.info(
                f"âœ… åˆ†æå®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(comments)} æ¡è¯„è®ºï¼Œå®¢æˆ·æ€»æ•°: {len(potential_customers)}ï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return {
                'aweme_id': aweme_id,
                'potential_customers': potential_customers,
                'customer_count': len(potential_customers),
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round(processing_time * 1000, 2)
            }
        except (ValidationError, ExternalAPIError) as e:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿™äº›å·²å¤„ç†çš„é”™è¯¯
            logger.error(f"è·å–æ½œåœ¨å®¢æˆ·æ—¶å‡ºé”™: {str(e)}")
            raise e
        except Exception as e:
            logger.error(f"è·å–æ½œåœ¨å®¢æˆ·æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            raise InternalServerError(detail=f"è·å–æ½œåœ¨å®¢æˆ·æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")

    async def get_keyword_potential_customers(
            self,
            keyword: str,
            batch_size: int = 30,
            customer_count: int = 100,
            video_concurrency: int = 5,
            ai_concurrency: int = 5,
            min_score: float = 50.0,
            max_score: float = 100.0,
            ins_filter: bool = False,
            twitter_filter: bool = False,
            region_filter: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        æ ¹æ®å…³é”®è¯è·å–æ½œåœ¨å®¢æˆ·

        Args:
            keyword (str): å…³é”®è¯
            batch_size (int, optional): æ¯æ‰¹å¤„ç†çš„è¯„è®ºæ•°é‡ï¼Œé»˜è®¤30
            customer_count (int, optional): æœ€å¤§æ½œåœ¨å®¢æˆ·æ•°é‡ï¼Œé»˜è®¤100
            video_concurrency (int, optional): è§†é¢‘å¤„ç†å¹¶å‘æ•°ï¼Œé»˜è®¤5
            ai_concurrency (int, optional): aiå¤„ç†å¹¶å‘æ•°ï¼Œé»˜è®¤5
            min_score (float, optional): æœ€å°å‚ä¸åº¦åˆ†æ•°ï¼Œé»˜è®¤50.0
            max_score (float, optional): æœ€å¤§å‚ä¸åº¦åˆ†æ•°ï¼Œé»˜è®¤100.0
            ins_filter (bool, optional): æ˜¯å¦è¿‡æ»¤Instagramä¸ºç©ºç”¨æˆ·ï¼Œé»˜è®¤False
            twitter_filter (bool, optional): æ˜¯å¦è¿‡æ»¤Twitterä¸ºç©ºç”¨æˆ·ï¼Œé»˜è®¤False
            region_filter (str, optional): åœ°åŒºè¿‡æ»¤ï¼Œé»˜è®¤None

        Returns:
            Dict[str, Any]: æ½œåœ¨å®¢æˆ·ä¿¡æ¯

        Raises:
            ValueError: å½“å‚æ•°æ— æ•ˆæ—¶
            RuntimeError: å½“åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
        """
        start_time = time.time()
        potential_customers = []  # æ½œåœ¨å®¢æˆ·åˆ—è¡¨

        try:
            if not keyword or not isinstance(keyword, str):
                raise ValueError("æ— æ•ˆçš„å…³é”®è¯")

            # è·å–æ¸…ç†åçš„è§†é¢‘æ•°æ®
            video_collector = VideoCollector(self.tikhub_api_key, self.tikhub_base_url)
            video_cleaner = VideoCleaner()
            raw_videos = await video_collector.collect_videos_by_keyword(keyword)
            cleaned_videos = await video_cleaner.clean_videos_by_keyword(raw_videos)

            videos_df = pd.DataFrame(cleaned_videos['videos'])
            aweme_ids = videos_df['aweme_id'].tolist()

            if not aweme_ids:
                logger.warning(f"æœªæ‰¾åˆ°ä¸å…³é”®è¯ {keyword} ç›¸å…³çš„è§†é¢‘")
                return {
                    'keyword': keyword,
                    'potential_customers': [],
                    'customer_count': 0,
                    'timestamp': datetime.now().isoformat()
                }

            logger.info(f"å¼€å§‹åˆ†æä¸å…³é”®è¯ {keyword} ç›¸å…³çš„ {len(videos_df)} ä¸ªè§†é¢‘ä»¥è¯†åˆ«æ½œåœ¨å®¢æˆ·")

            # æŒ‰ç…§è§†é¢‘å¹¶å‘æ•°å¤„ç†è§†é¢‘
            for i in range(0, len(aweme_ids), video_concurrency):
                if self.customer_count >= customer_count: # å¦‚æœå·²ç»è¾¾åˆ°æœ€å¤§æ½œåœ¨å®¢æˆ·æ•°é‡ï¼Œåœæ­¢å¤„ç†
                    self.comment_collector.status = False  # åœæ­¢æ”¶é›†è¯„è®º
                    self.comment_cleaner.status = False  # åœæ­¢æ¸…æ´—è¯„è®º
                    logger.info(f"å·²ç»è¾¾åˆ°æœ€å¤§æ½œåœ¨å®¢æˆ·æ•°é‡ {customer_count}ï¼Œåœæ­¢å¤„ç†")
                    break
                batch_aweme_ids = aweme_ids[i:i + video_concurrency]
                logger.info(f"å¤„ç†è§†é¢‘æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_aweme_ids)}")
                tasks = [
                    self.get_potential_customers(
                        aweme_id,
                        batch_size,
                        customer_count,
                        ai_concurrency,
                        min_score,
                        max_score,
                        ins_filter,
                        twitter_filter,
                        region_filter
                    )
                    for aweme_id in batch_aweme_ids
                ]
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)

                for j, result in enumerate(batch_results):
                    if isinstance(result, Exception) or not result:
                        logger.error(f"è§†é¢‘ {aweme_ids[i + j]} å¤„ç†å¤±è´¥/åœæ­¢å¤„ç†: {str(result)}")
                    else:
                        potential_customers.extend(result.get('potential_customers', []))
                        logger.info(f"è§†é¢‘ {aweme_ids[i + j]} å¤„ç†å®Œæˆ")


            # æ ¹æ®æ½œåœ¨ä»·å€¼è¿‡æ»¤å’Œæ’åº
            potential_customers_df = pd.DataFrame(potential_customers)
            filtered_df = potential_customers_df[
                potential_customers_df['potential_value'].between(min_score, max_score)
            ].sort_values(by='potential_value', ascending=False)

            # è®¡ç®—å¹³å‡æ½œåœ¨ä»·å€¼
            avg_value = filtered_df['potential_value'].mean() if not filtered_df.empty else 0

            processing_time = time.time() - start_time
            return {
                'keyword': keyword,
                'customer_count': len(potential_customers),
                'potential_customers': potential_customers,
                'min_engagement_score': min_score,
                'max_engagement_score': max_score,
                'average_potential_value': round(avg_value, 2),
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round(processing_time * 1000, 2)
            }
        except ValueError:
            # ç›´æ¥å‘ä¸Šä¼ é€’éªŒè¯é”™è¯¯
            raise ValueError
        except RuntimeError:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿è¡Œæ—¶é”™è¯¯
            raise RuntimeError
        except Exception as e:
            logger.error(f"è·å–å…³é”®è¯æ½œåœ¨å®¢æˆ·æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            raise RuntimeError(f"è·å–å…³é”®è¯æ½œåœ¨å®¢æˆ·æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")


    async def _analyze_aspect(
            self,
            aspect_type: str,
            comment_data: List[Dict[str, Any]],
    ) -> Optional[List[Dict[str, Any]]]:
        """
        é€šç”¨åˆ†ææ–¹æ³•ï¼Œæ ¹æ®ä¸åŒçš„åˆ†æç±»å‹è°ƒç”¨ChatGPTæˆ–Claude AIæ¨¡å‹ã€‚

        Args:
            aspect_type (str): éœ€è¦åˆ†æçš„ç±»å‹ (purchase_intent)
            max_count (int): æœ€å¤§åˆ†ææ•°é‡
            comment_data (List[Dict[str, Any]]): éœ€è¦åˆ†æçš„è¯„è®ºåˆ—è¡¨

        Returns:
            Optional[List[Dict[str, Any]]]: AIè¿”å›çš„åˆ†æç»“æœï¼Œå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸

        Raises:
            ValidationError: å½“aspect_typeæ— æ•ˆæ—¶
            ExternalAPIError: å½“è°ƒç”¨AIæœåŠ¡æ—¶å‡ºé”™
        """
        try:
            if aspect_type not in self.analysis_types:
                raise ValidationError(detail=f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {aspect_type}", field="aspect_type")

            if not comment_data:
                logger.warning("è¯„è®ºæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡åˆ†æ")
                return []

            # è·å–åˆ†æçš„ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤º
            aspect_config = self.user_prompts[aspect_type]
            sys_prompt = self.system_prompts[aspect_type]
            user_prompt = (
                f"Analyze the {aspect_config['description']} for the following comments:\n"
                f"{json.dumps(comment_data, ensure_ascii=False)}"
            )

            # ä¸ºé¿å…tokené™åˆ¶ï¼Œé™åˆ¶è¯„è®ºæ–‡æœ¬é•¿åº¦
            for comment in comment_data:
                if 'text' in comment and len(comment['text']) > 1000:
                    comment['text'] = comment['text'][:997] + "..."

            # è°ƒç”¨AIè¿›è¡Œåˆ†æï¼Œä¼˜å…ˆä½¿ç”¨ChatGPTï¼Œå¤±è´¥æ—¶å°è¯•Claude
            try:
                response = await self.chatgpt.chat(
                    system_prompt=sys_prompt,
                    user_prompt=user_prompt
                )

                # è§£æChatGPTè¿”å›çš„ç»“æœ
                analysis_results = response["choices"][0]["message"]["content"].strip()

            except ExternalAPIError as e:
                logger.warning(f"ChatGPTåˆ†æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Claude: {str(e)}")
                try:
                    # å°è¯•ä½¿ç”¨Claudeä½œä¸ºå¤‡ä»½
                    response = await self.claude.chat(
                        system_prompt=sys_prompt,
                        user_prompt=user_prompt
                    )
                    analysis_results = response["choices"][0]["message"]["content"].strip()
                except Exception as claude_error:
                    logger.error(f"Claudeåˆ†æä¹Ÿå¤±è´¥: {str(claude_error)}")
                    raise ExternalAPIError(
                        detail="æ‰€æœ‰AIæœåŠ¡å‡æ— æ³•å®Œæˆåˆ†æ",
                        service="AI"
                    )

            # å¤„ç†è¿”å›çš„JSONæ ¼å¼ï¼ˆå¯èƒ½åŒ…å«åœ¨Markdownä»£ç å—ä¸­ï¼‰
            analysis_results = re.sub(
                r"```json\n|\n```|```|\n",
                "",
                analysis_results.strip()
            )

            try:
                analysis_result = json.loads(analysis_results)
                return analysis_result
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æé”™è¯¯: {str(e)}, åŸå§‹å†…å®¹: {analysis_results[:200]}...")
                raise ExternalAPIError(
                    detail="AIè¿”å›çš„ç»“æœæ— æ³•è§£æä¸ºJSON",
                    service="AI",
                    original_error=e
                )

        except ValidationError:
            # ç›´æ¥å‘ä¸Šä¼ é€’éªŒè¯é”™è¯¯
            raise
        except ExternalAPIError:
            # ç›´æ¥å‘ä¸Šä¼ é€’APIé”™è¯¯
            raise
        except Exception as e:
            logger.error(f"åˆ†æè¯„è®ºæ–¹é¢æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            raise InternalServerError(f"åˆ†æè¯„è®ºæ–¹é¢æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")

    @staticmethod
    def _calculate_engagement_score(
            sentiment: str,
            purchase_intent: bool,
            interest_level: str
    ) -> float:
        """
        è®¡ç®—æ½œåœ¨å®¢æˆ·çš„å‚ä¸åº¦åˆ†æ•°

        Args:
            sentiment (str): æƒ…æ„Ÿåˆ†æç»“æœ ('positive', 'neutral', 'negative')
            purchase_intent (bool): æ˜¯å¦æœ‰è´­ä¹°æ„å›¾
            interest_level (str): å…´è¶£æ°´å¹³ ('high', 'medium', 'low')

        Returns:
            float: å‚ä¸åº¦åˆ†æ•° (0-100)
        """
        try:
            # å‚æ•°éªŒè¯å’Œæ ‡å‡†åŒ–
            if not isinstance(sentiment, str):
                sentiment = str(sentiment).lower()
            else:
                sentiment = sentiment.lower()

            if not isinstance(purchase_intent, bool):
                # å°è¯•è½¬æ¢ä¸ºå¸ƒå°”å€¼
                if isinstance(purchase_intent, str):
                    purchase_intent = purchase_intent.lower() in ['true', '1', 'yes', 't']
                else:
                    purchase_intent = bool(purchase_intent)

            if not isinstance(interest_level, str):
                interest_level = str(interest_level).lower()
            else:
                interest_level = interest_level.lower()

            # ä¿®æ­£æƒ…æ„Ÿæ ‡ç­¾
            if sentiment in ['neg', 'negative']:
                sentiment = 'negative'
            elif sentiment in ['pos', 'positive']:
                sentiment = 'positive'
            elif sentiment not in ['neutral']:
                sentiment = 'neutral'  # é»˜è®¤ä¸ºä¸­æ€§

            # å¤„ç†å…´è¶£æ°´å¹³ä¸­å€¼çš„ä¸åŒè¡¨ç¤º
            if interest_level in ['mid', 'medium']:
                interest_level = 'medium'
            elif interest_level not in ['high', 'low']:
                interest_level = 'low'  # é»˜è®¤ä¸ºä½å…´è¶£

            # 1. æƒ…æ„Ÿè½¬æ¢ (0-1 scale)
            sentiment_score = {
                'positive': 1.0,
                'neutral': 0.5,
                'negative': 0.0
            }.get(sentiment, 0.5)  # é»˜è®¤ä¸ºä¸­æ€§

            # 2. è´­ä¹°æ„å›¾åˆ†æ•°
            intent_score = 1.0 if purchase_intent else 0.0

            # 3. å…´è¶£æ°´å¹³åˆ†æ•°
            interest_score = {
                'high': 1.0,
                'medium': 0.5,
                'low': 0.2
            }.get(interest_level, 0.5)  # é»˜è®¤ä¸ºä¸­ç­‰

            # æ ¹æ®åŠ æƒå¹³å‡è®¡ç®—æ½œåœ¨ä»·å€¼
            potential_value = (
                                      0.3 * sentiment_score +
                                      0.4 * intent_score +
                                      0.3 * interest_score
                              ) * 100  # ç¼©æ”¾åˆ°0-100

            return round(potential_value, 2)

        except Exception as e:
            logger.error(f"è®¡ç®—å‚ä¸åº¦åˆ†æ•°æ—¶å‡ºé”™: {str(e)}")
            # è¿”å›é»˜è®¤å€¼
            return 0.0

async def main():
    agent = CustomerAgent()
    # è·å–æ½œåœ¨å®¢æˆ·
    result = await agent.get_keyword_potential_customers("iphone 13", customer_count=400, min_score=50, max_score=100)

if __name__ == "__main__":
    asyncio.run(main())

