# -*- coding: utf-8 -*-
"""
@file: sentiment_agent.py
@desc: å¤„ç†TikTokè¯„è®ºçš„ä»£ç†ç±»ï¼Œæä¾›è¯„è®ºè·å–ã€èˆ†æƒ…åˆ†æå’Œé»‘ç²‰è¯†åˆ«åŠŸèƒ½
@auth: Callmeiks
"""

import json
import re
from datetime import datetime
from typing import Dict, Any, List, Optional, AsyncGenerator
from collections import Counter
import asyncio
import time
import markdown

import numpy as np
import pandas as pd
from dotenv import load_dotenv
import os

from app.utils.logger import setup_logger
from services.ai_models.chatgpt import ChatGPT
from services.ai_models.claude import Claude
from services.cleaner.tiktok.comment_cleaner import CommentCleaner
from services.crawler.tiktok.comment_crawler import CommentCollector
from app.config import settings
from app.core.exceptions import ValidationError, ExternalAPIError, InternalServerError

# è®¾ç½®æ—¥å¿—è®°å½•å™¨
logger = setup_logger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class SentimentAgent:
    """å¤„ç†TikTokè¯„è®ºçš„ä»£ç†ç±»ï¼Œæä¾›è¯„è®ºè·å–ã€èˆ†æƒ…åˆ†æå’Œé»‘ç²‰è¯†åˆ«åŠŸèƒ½"""

    def __init__(self, tikhub_api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–SentimentAgentï¼ŒåŠ è½½APIå¯†é’¥å’Œæç¤ºæ¨¡æ¿

        Args:
            tikhub_api_key: TikHub APIå¯†é’¥
            tikhub_base_url: TikHub APIåŸºç¡€URL
        """
        # åˆå§‹åŒ–AIæ¨¡å‹å®¢æˆ·ç«¯
        self.chatgpt = ChatGPT()
        self.claude = Claude()

        # åˆå§‹åŒ–æ”¶é›†å™¨å’Œæ¸…æ´å™¨
        self.comment_collector = CommentCollector(tikhub_api_key)
        self.comment_cleaner = CommentCleaner()

        # ä¿å­˜TikHub APIé…ç½®
        self.tikhub_api_key = tikhub_api_key
        self.tikhub_base_url = settings.TIKHUB_BASE_URL

        # å¦‚æœæ²¡æœ‰æä¾›TikHub APIå¯†é’¥ï¼Œè®°å½•è­¦å‘Š
        if not self.tikhub_api_key:
            logger.warning("æœªæä¾›TikHub APIå¯†é’¥ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

        self.analysis_types = ['sentiment', 'relationship', 'toxicity']

        # åŠ è½½ç³»ç»Ÿå’Œç”¨æˆ·æç¤º
        self._load_system_prompts()
        self._load_user_prompts()

    def _load_system_prompts(self) -> None:
        """åŠ è½½ç³»ç»Ÿæç¤ºç”¨äºä¸åŒçš„è¯„è®ºåˆ†æç±»å‹"""
        self.system_prompts = {
            'sentiment': """You are an AI trained to analyze social media comments on TikTok videos. Your task is to categorize and summarize how commenters react to a given video.
                For each comment in the provided list, analyze:
                1. Sentiment (positive, negative, or neutral)
                2. Emotion (e.g., excitement, amusement, frustration, curiosity, etc.)
                3. Engagement Type (e.g., supportive, critical, humorous, questioning, spam)
                4. Key Themes (e.g., reaction to video content, reference to trends, personal anecdotes, meme usage)
                5. Virality Indicators (e.g., high engagement phrases, common phrases from viral trends, use of emojis, repeated comment patterns)
                
                Return the analysis in the following JSON format, and comment_id should still remain the same as input data:
                [
                    {
                        "comment_id": "comment ID from input data",
                        "text": "comment text",
                        "sentiment": "positive/negative/neutral",
                        "emotion": "emotion_label",
                        "engagement_type": "supportive/critical/humorous/questioning/spam",
                        "key_themes": ["theme1", "theme2"],
                        "virality_indicators": ["emoji", "phrase", "meme_reference"],
                    }
                ]
                
                Guidelines:
                - Identify emotions based on wording, punctuation, and emojis.
                - Consider trends and viral elements influencing reactions.
                - If a comment uses humor or sarcasm, categorize it accordingly.
                - If a comment references a meme or viral phrase, list it as a key theme.
                - Comments containing excessive emojis, repeated phrases, or engagement-bait (e.g., "like if you agree") should be marked as potential virality indicators.
                
                Respond with a JSON array containing analysis for all comments.
                """,

            'relationship': """You are an AI trained to analyze audience sentiment and engagement toward an influencer or creator. Your task is to assess how commenters perceive and interact with the influencer.
                For each comment, analyze:
                1. **Trust Level:** (loyal fan, skeptical, indifferent)
                2. **Tone Toward Influencer/Brand:** (supportive, critical, neutral)
                3. **Fandom Level:** (casual viewer, superfan, first-time viewer)
                4. **Previous Knowledge of Influencer:** (new follower, returning audience, long-time fan)
                5. **Engagement Type:** (praise, criticism, joke, curiosity, casual remark)
                
                **JSON Output Format:**
                [
                    {
                        "comment_id": "comment ID from input data",
                        "text": "comment text",
                        "trust_level": "loyal_fan/skeptical/indifferent",
                        "tone_toward_influencer": "supportive/critical/neutral",
                        "fandom_level": "casual_viewer/superfan/first_time_viewer",
                        "previous_knowledge": "new_follower/returning_audience/long_time_fan",
                        "engagement_type": "praise/criticism/joke/curiosity/casual_remark",
                    }
                ]
                
                **Guidelines:**
                - Identify loyalty through repeated engagement or references to past content.
                - Detect tone based on word choice, punctuation, and emojis.
                - Recognize when users joke, question, or provide constructive criticism.
                - Assess engagement depth (quick reaction vs. detailed discussion).
                
                Respond with a JSON array containing the analysis for all comments.
                """,

            'toxicity': """You are an AI trained to analyze social media comments for harmful, inappropriate,negative_product_review, negative_service_review, negative_shop_review or spam content. Your task is to detect and categorize toxicity levels in the provided comments.
                For each comment, analyze:
                1. **Toxicity Level:** (low, medium, high)
                2. **Type of Toxicity:** (e.g., negative_product_review, negative_service_review, negative_shop_review, hate speech, personal attack, trolling, misinformation, spam)
                3. **Report Worthiness:** (should report, needs review, not harmful)
                4. **Potential Community Guidelines Violation:** (yes/no)
                5. **Severity Score:** (scale from 1-10, with 10 being highly toxic)
        
                **JSON Output Format:**
                [
                    {
                        "comment_id": "comment ID from input data",
                        "text": "comment text",
                        "toxicity_level": "low/medium/high",
                        "toxicity_type": "negative_product_review/negative_service_review/negative_shop_review/hate_speech/personal_attack/trolling/misinformation/spam",
                        "report_worthiness": "should_report/needs_review/not_harmful",
                        "community_guidelines_violation": true/false,
                        "severity_score": "1-10",
                    }
                ]
        
                **Guidelines:**
                - Detect offensive language, threats, or harmful intent.
                - Recognize subtle toxicity, sarcasm, and coded language.
                - Mark spam comments with excessive emojis, engagement-bait phrases, or promotional links.
                - Ensure fairness by considering context and common internet slang.
                - emojis are not consider as spam.
        
                Respond with a JSON array containing the analysis for all comments.
                """,

            'relationship_report': """You are a social media analytics expert specializing in influencer-audience relationships. Your task is to create an engaging report analyzing comment data to reveal audience connection patterns and community dynamics.
                Report Sections:
                1. Report Metadata (video ID, total comments, analysis timestamp)
                2. Community Insight Summary (2-3 sentences highlighting key relationship patterns found in the data)
                3. Audience Connection Analysis (analyze specific ways commenters relate to the creator - personal stories shared, questions asked, consistent engagement patterns)
                4. Trust & Loyalty Indicators (markdown table showing metrics like returning commenters, defense of creator, personal disclosure levels)
                5. Engagement Quality Assessment (analyze depth of comments, conversation threads, and emotional investment)
                6. Audience Segmentation (identify distinct audience groups based on comment patterns and how they relate to the creator)
                7. Relationship Growth Opportunities (2-3 specific, data-backed suggestions to strengthen audience bonds)
                
                Focus on revealing relationship patterns from the input data rather than generic advice. Identify how the audience perceives their relationship with the creator, what connection points resonate most, and where deeper engagement opportunities exist. Keep the report under 500 words.""",

            'sentiment_report': """You are a content performance analyst specializing in audience emotional responses. Your task is to create an insightful report analyzing comment data to reveal how content emotionally resonates with the audience.
                Report Sections:
                1. Report Metadata (video ID, total comments, analysis timestamp)
                2. Emotional Response Overview (2-3 sentences summarizing the dominant emotional patterns found in comments)
                3. Sentiment Analysis (markdown table showing positive/negative/neutral distribution with specific emotion subcategories)
                4. Emotional Triggers (analyze which specific content elements/moments generated the strongest emotional responses)
                5. Audience Reaction Patterns (identify how emotions spread or change through comment threads)
                6. Sentiment by Audience Segment (how different viewer groups emotionally responded)
                7. Content Resonance Insights (which emotional appeals were most effective)
                8. Strategic Recommendations (2-3 actionable ways to enhance positive emotional engagement based on the data)
                
                Focus on extracting emotional patterns directly from the input data. Analyze the specific language, expressions, and reactions that reveal audience emotional states and how they connect to content elements. Keep the report under 450 words.""",

            'toxicity_report': """You are an expert content moderator and community safety analyst. Your task is to create a clear, concise report analyzing comment data to reveal community health and safety concerns.
                Report Sections:
                1. Report Metadata (video ID, total comments, analysis timestamp)
                2. Safety Assessment Summary (2-3 sentences highlighting the overall community health based on toxicity metrics)
                3. Toxicity Analysis (markdown table showing types and levels of problematic content identified)
                4. Context Pattern Analysis (analyze when/where toxicity appears - specific topics, timestamps, or triggers)
                5. Impact Assessment (analyze how toxic comments affect overall engagement and community interaction)
                6. Moderation Priority Areas (identify specific types of concerning content requiring attention)
                7. Community Management Recommendations (2-3 actionable, data-backed strategies to improve community health)
                
                Focus on presenting objective analysis from the input data rather than subjective judgments. Distinguish between genuine community concerns and minor issues. Provide balanced perspective that helps creators understand real community health without overemphasizing isolated incidents. Keep the report under 400 words."""
        }

    def _load_user_prompts(self) -> None:
        """åŠ è½½ç”¨æˆ·æç¤ºç”¨äºä¸åŒçš„è¯„è®ºåˆ†æç±»å‹"""
        self.user_prompts = {
            'sentiment': {
                'description': "sentiment and engagement analysis",
            },
            'relationship': {
                'description': "relationship and engagement analysis",
            },
            'toxicity': {
                'description': "toxicity, spam analysis",
            },

        }

    """---------------------------------------------é€šç”¨æ–¹æ³•/å·¥å…·ç±»æ–¹æ³•---------------------------------------------"""

    async def _analyze_aspect(
            self,
            aspect_type: str,
            comment_data: List[Dict[str, Any]],
    ) -> Dict[str, str | Any]:
        """
        é€šç”¨åˆ†ææ–¹æ³•ï¼Œæ ¹æ®ä¸åŒçš„åˆ†æç±»å‹è°ƒç”¨ChatGPTæˆ–Claude AIæ¨¡å‹ã€‚

        æ­¥éª¤:
        1. éªŒè¯åˆ†æç±»å‹æ˜¯å¦æ”¯æŒ
        2. æ„é€ åˆ†ææç¤º
        3. è°ƒç”¨AIæ¨¡å‹è¿›è¡Œåˆ†æ
        4. è§£æå¹¶è¿”å›åˆ†æç»“æœ

        Args:
            aspect_type: éœ€è¦åˆ†æçš„ç±»å‹ (purchase_intent)
            comment_data: éœ€è¦åˆ†æçš„è¯„è®ºåˆ—è¡¨

        Returns:
            Optional[List[Dict[str, Any]]]: AIè¿”å›çš„åˆ†æç»“æœï¼Œå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸

        Raises:
            ValidationError: å½“aspect_typeæ— æ•ˆæ—¶
            ExternalAPIError: å½“è°ƒç”¨AIæœåŠ¡æ—¶å‡ºé”™
        """

        # éªŒè¯åˆ†æç±»å‹æ˜¯å¦æ”¯æŒ
        if aspect_type not in self.analysis_types:
            raise ValidationError(detail=f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {aspect_type}", field="aspect_type")

        # æ£€æŸ¥è¯„è®ºæ•°æ®æ˜¯å¦ä¸ºç©º
        if not comment_data:
            logger.warning("è¯„è®ºæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡åˆ†æ")
            raise ValidationError(detail="è¯„è®ºæ•°æ®ä¸ºç©ºï¼Œæ— æ³•åˆ†æ", field="comment_data")

        try:
            # è·å–åˆ†æçš„ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤º
            sys_prompt = self.system_prompts[aspect_type]
            user_prompt = (
                f"Analyze the purchase intent for the following comments:\n"
                f"{json.dumps(comment_data, ensure_ascii=False)}"
            )

            # ä¸ºé¿å…tokené™åˆ¶ï¼Œé™åˆ¶è¯„è®ºæ–‡æœ¬é•¿åº¦
            for comment in comment_data:
                if 'text' in comment and len(comment['text']) > 1000:
                    comment['text'] = comment['text'][:997] + "..."

            # å°è¯•ä½¿ç”¨ChatGPTè¿›è¡Œåˆ†æ
            response = await self.chatgpt.chat(
                system_prompt=sys_prompt,
                user_prompt=user_prompt
            )

            # è§£æChatGPTè¿”å›çš„ç»“æœ
            analysis_results = response['response']["choices"][0]["message"]["content"].strip()

            # å¤„ç†è¿”å›çš„JSONæ ¼å¼ï¼ˆå¯èƒ½åŒ…å«åœ¨Markdownä»£ç å—ä¸­ï¼‰
            analysis_results = re.sub(
                r"```json\n|\n```|```|\n",
                "",
                analysis_results.strip()
            )

            analysis_results = json.loads(analysis_results)

            result = {
                "response": analysis_results,
                "cost": response["cost"]
            }
            return result
        except (ValidationError, InternalServerError, ExternalAPIError):
            raise
        except Exception as e:
            logger.error(f"åˆ†æè¯„è®ºæ–¹é¢æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            raise InternalServerError(f"åˆ†æè¯„è®ºæ–¹é¢æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")

    async def generate_analysis_report(self, aweme_id: str, analysis_type: str, data: Dict[str, Any]) -> Dict[str, str | Any]:
        """
        ç”ŸæˆæŠ¥å‘Šå¹¶è½¬æ¢ä¸ºHTML

        Args:
            aweme_id (str): è§†é¢‘ ID
            analysis_type (str): åˆ†æç±»å‹
            data (Dict[str, Any]): åˆ†ææ•°æ®

        Returns:
            str: HTMLæŠ¥å‘Šçš„æœ¬åœ°æ–‡ä»¶URL
        """
        if analysis_type not in self.system_prompts:
            raise ValueError(f"Invalid report type: {analysis_type}. Choose from {self.system_prompts.keys()}")

        try:
            # è·å–ç³»ç»Ÿæç¤º
            sys_prompt = self.system_prompts[analysis_type]

            # è·å–ç”¨æˆ·æç¤º
            user_prompt = f"Generate a report for the {analysis_type} analysis based on the following data:\n{json.dumps(data, ensure_ascii=False)}, for video ID: {aweme_id}"

            # ç”ŸæˆæŠ¥å‘Š
            response = await self.chatgpt.chat(
                system_prompt=sys_prompt,
                user_prompt=user_prompt
            )

            report = response['response']["choices"][0]["message"]["content"].strip()

            # ä¿å­˜MarkdownæŠ¥å‘Š
            report_dir = "reports"
            os.makedirs(report_dir, exist_ok=True)

            report_md_path = os.path.join(report_dir, f"report_{aweme_id}.md")
            with open(report_md_path, "w", encoding="utf-8") as f:
                f.write(report)

            # è½¬æ¢ä¸ºHTML
            html_content = self.convert_markdown_to_html(report, f"{analysis_type.title()} Analysis for {aweme_id}")
            html_filename = f"report_{aweme_id}.html"
            html_path = os.path.join(report_dir, html_filename)

            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)

            # ç”Ÿæˆæœ¬åœ°æ–‡ä»¶URL
            absolute_path = os.path.abspath(html_path)

            # æ„å»ºfile://åè®®URL
            file_url = f"file://{absolute_path}"

            # ç¡®ä¿è·¯å¾„åˆ†éš”ç¬¦æ˜¯URLå…¼å®¹çš„
            if os.name == 'nt':  # Windowsç³»ç»Ÿ
                # Windowsè·¯å¾„éœ€è¦è½¬æ¢ä¸ºURLæ ¼å¼
                file_url = file_url.replace('\\', '/')

            return {
                "report_url": file_url,
                "cost": response["cost"]
            }
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            raise InternalServerError(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")

    def convert_markdown_to_html(self, markdown_content: str, title: str = "Analysis Report") -> str:
        """
        å°†Markdownå†…å®¹è½¬æ¢ä¸ºHTML

        Args:
            markdown_content (str): Markdownå†…å®¹
            title (str): HTMLé¡µé¢æ ‡é¢˜

        Returns:
            str: HTMLå†…å®¹
        """

        # è½¬æ¢Markdownä¸ºHTML
        html_content = markdown.markdown(
            markdown_content,
            extensions=['tables', 'fenced_code', 'codehilite', 'toc']
        )

        # åˆ›å»ºå®Œæ•´HTMLæ–‡æ¡£
        css = """
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; color: #333; }
        h1, h2, h3 { margin-top: 1.5em; color: #111; }
        pre { background-color: #f6f8fa; border-radius: 3px; padding: 16px; overflow: auto; }
        code { font-family: SFMono-Regular, Consolas, Menlo, monospace; background-color: #f6f8fa; padding: 0.2em 0.4em; border-radius: 3px; }
        table { border-collapse: collapse; width: 100%; margin-bottom: 1em; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f6f8fa; }
        """

        html_document = f"""<!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title}</title>
        <style>{css}</style>
    </head>
    <body>
        <h1>{title}</h1>
        {html_content}
    </body>
    </html>
        """

        return html_document

    """---------------------------------------------è·å–è§†é¢‘è¯„è®º-----------------------------------------------"""

    async def fetch_video_comments(
            self,
            aweme_id: str,
            ins_filter: bool = False,
            twitter_filter: bool = False,
            region_filter: Optional[str] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è·å–æŒ‡å®šè§†é¢‘çš„æ¸…ç†åçš„è¯„è®ºæ•°æ®

        Args:
            aweme_id: è§†é¢‘ID
            ins_filter: æ˜¯å¦è¿‡æ»¤Instagramä¸ºNoneçš„è¯„è®º
            twitter_filter: æ˜¯å¦è¿‡æ»¤Twitterä¸ºNoneçš„è¯„è®º
            region_filter: è¯„è®ºåŒºåŸŸè¿‡æ»¤å™¨ï¼Œä¾‹å¦‚"US"ï¼Œ"GB"ç­‰

        Returns:
            Dict[str, Any]: æ¸…ç†åçš„è¯„è®ºæ•°æ®ï¼ŒåŒ…å«è§†é¢‘IDå’Œè¯„è®ºåˆ—è¡¨

        Raises:
            ValidationError: å½“aweme_idä¸ºç©ºæˆ–æ— æ•ˆæ—¶
            ExternalAPIError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
        """
        if not aweme_id or not isinstance(aweme_id, str):
            raise ValidationError(detail="aweme_idå¿…é¡»æ˜¯æœ‰æ•ˆçš„å­—ç¬¦ä¸²", field="aweme_id")

        start_time = time.time()
        comments = []
        total_comments = 0

        logger.info(f"ğŸ” å¼€å§‹è·å–è§†é¢‘ {aweme_id} çš„è¯„è®º")

        try:
            # è·å–è¯„è®º
            async for comment_batch in self.comment_collector.stream_video_comments(aweme_id):
                # å¯¹æ¯æ‰¹è¯„è®ºè¿›è¡Œæ¸…æ´—
                cleaned_comments = await self.comment_cleaner.clean_video_comments(comment_batch)

                # è½¬æ¢ä¸ºDataFrameä¾¿äºå¤„ç†
                comments_df = pd.DataFrame(cleaned_comments)

                # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                if ins_filter:
                    comments_df = comments_df[comments_df['ins_id'] != '']
                if twitter_filter:
                    comments_df = comments_df[comments_df['twitter_id'] != '']
                if region_filter:
                    comments_df = comments_df[comments_df['commenter_region'] == region_filter]

                total_comments += len(comments_df)

                comments.extend(comments_df.to_dict(orient='records'))

                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'message': f"å·²è·å– {total_comments} æ¡è¯„è®º",
                    'total_collected_comments': total_comments,
                    'current_batch_count': len(comments_df),
                    'current_batch_comments': comments_df.to_dict(orient='records'),
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 100, 2)
                }

            # è®°å½•è·å–è¯„è®ºç»“æŸ
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'total_collected_comments': total_comments,
                'comments': comments,
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 100, 2)
            }
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘è¯„è®ºæ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
            yield {
                'aweme_id': aweme_id,
                'is_complete': False,
                'error': str(e),
                'total_collected_comments': total_comments,
                'comments': comments,
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 100, 2)
            }
            return

    """---------------------------------------------æƒ…æ„Ÿåˆ†æ-----------------------------------------------"""

    async def fetch_sentiment_analysis(self, aweme_id: str, batch_size: int = 30, concurrency: int = 5) -> AsyncGenerator[Dict[str, Any], None]:
        """
        åˆ†ææŒ‡å®šè§†é¢‘çš„è¯„è®ºæƒ…æ„Ÿ

        Args:
            aweme_id (str): è§†é¢‘ID
            batch_size (int, optional): æ¯æ‰¹å¤„ç†çš„è¯„è®ºæ•°é‡ï¼Œé»˜è®¤30
            concurrency (int, optional): å¹¶å‘å¤„ç†çš„æ‰¹æ¬¡æ•°é‡ï¼Œé»˜è®¤5

        Returns:
            Dict[str, Any]: æƒ…æ„Ÿåˆ†æç»“æœ

        Raises:
            ValidationError: å½“aweme_idä¸ºç©ºæˆ–æ— æ•ˆæ—¶
            ExternalAPIError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
            InternalServerError: å½“åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
        """

        if not aweme_id:
            raise ValidationError(detail="aweme_idä¸èƒ½ä¸ºç©º", field="aweme_id")

        if batch_size <= 0 or batch_size > settings.MAX_BATCH_SIZE:
            raise ValidationError(
                detail=f"batch_sizeå¿…é¡»åœ¨1å’Œ{settings.MAX_BATCH_SIZE}ä¹‹é—´",
                field="batch_size"
            )

        start_time = time.time()
        comments = []
        results = []
        analysis_summary = {}
        total_collected_comments = 0
        total_analyzed_comments = 0
        llm_processing_cost = {'total_cost': 0.0, 'input_cost': 0.0, 'output_cost': 0.0}

        try:
            # æµå¼è·å–è¯„è®º
            async for comments_batch in self.fetch_video_comments(aweme_id):
                if 'error' not in comments_batch and not comments_batch['is_complete']:
                    comments.append(comments_batch['current_batch_comments'])
                    total_collected_comments += comments_batch['current_batch_count']
                else:
                    comments = comments_batch.get('comments', [])
                    total_collected_comments = comments_batch.get('total_comments', 0)

                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': total_analyzed_comments,
                    'analysis_summary': analysis_summary,
                    'message': f"æ­£åœ¨è·å–è¯„è®º: {total_collected_comments} æ¡",
                    'timestamp': comments_batch.get('timestamp', datetime.now().isoformat()),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # æ•°æ®éªŒè¯
            if len(comments) == 0:
                raise ValidationError(detail="è·å–åˆ°çš„è¯„è®ºæ•°æ®ä¸ºç©º", field="comments")

            comments_df = pd.DataFrame(comments)

            if 'text' not in comments_df.columns:
                raise ValidationError(detail="è¯„è®ºæ•°æ®å¿…é¡»åŒ…å«'text'åˆ—", field="comments")

            # éªŒè¯å’Œè°ƒæ•´æ‰¹å¤„ç†å‚æ•°
            batch_size = min(batch_size, settings.MAX_BATCH_SIZE)
            concurrency = min(concurrency, 10)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º10

            # åˆ†æ‰¹å¤„ç†DataFrame
            num_splits = max(1, len(comments_df) // batch_size + (1 if len(comments_df) % batch_size > 0 else 0))
            comment_batches = np.array_split(comments_df, num_splits)

            # é¿å…ç©ºæ‰¹æ¬¡
            comment_batches = [batch for batch in comment_batches if not batch.empty]

            if not comment_batches:
                raise InternalServerError("åˆ†å‰²åçš„æ‰¹æ¬¡æ•°æ®ä¸ºç©º")

            avg_batch_size = len(comment_batches[0]) if comment_batches else 0

            # é€šçŸ¥å¼€å§‹åˆ†æ
            yield {
                'aweme_id': aweme_id,
                'is_complete': False,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': total_analyzed_comments,
                'analysis_summary': analysis_summary,
                'message': f"å¼€å§‹èˆ†æƒ…åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

            logger.info(
                f"å¼€å§‹èˆ†æƒ…åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º"
            )

            # æ‰¹æ¬¡å¤„ç†
            for i in range(0, len(comment_batches), concurrency):
                batch_group = comment_batches[i:i + concurrency]

                # è®°å½•å½“å‰å¹¶å‘ç»„çš„èŒƒå›´
                batch_indices = [
                    f"{batch.index[0]}-{batch.index[-1]}" for batch in batch_group
                ]
                logger.info(
                    f"âš¡ å¤„ç†æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}"
                )

                # å¹¶å‘æ‰§è¡Œæ‰¹å¤„ç†ä»»åŠ¡
                tasks = [
                    self._analyze_aspect('sentiment', batch[['text', 'comment_id']].to_dict('records'))
                    for batch in batch_group
                ]

                batch_results = await asyncio.gather(*tasks, return_exceptions=True)

                # å¤„ç†ç»“æœï¼Œè¿‡æ»¤æ‰å¼‚å¸¸
                error_count = 0

                for j, result in enumerate(batch_results):
                    if isinstance(result, Exception):
                        error_msg = f"æ‰¹æ¬¡ {i + j + 1} åˆ†æå¤±è´¥: {str(result)}"
                        logger.error(error_msg)
                        error_count += 1
                    else:
                        print(result)
                        results.extend(result['response'])
                        llm_processing_cost['total_cost'] += result['cost']['total_cost']
                        llm_processing_cost['input_cost'] += result['cost']['input_cost']
                        llm_processing_cost['output_cost'] += result['cost']['output_cost']

                # åªåœ¨æœ‰é”™è¯¯æ—¶æ‰å‘é€é”™è¯¯è¿›åº¦æ›´æ–°
                if error_count > 0:
                    raise InternalServerError(f"æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)} åˆ†æå¤±è´¥")

                # å‘é€è¿›åº¦æ›´æ–°
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(results),
                    'analysis_summary': analysis_summary,
                    'message': f"å·²åˆ†ææ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}ï¼Œç»§ç»­å¤„ç†...",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            logger.info(len(results))

            # åˆå¹¶æ‰€æœ‰åˆ†æç»“æœ
            try:
                # åˆ›å»ºç»“æœDataFrame
                if not results:
                    raise InternalServerError("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœ")
                analysis_df = pd.DataFrame(results)
                merged_df = pd.merge(comments_df, analysis_df, on='comment_id', how='left')

                # å¤„ç†é‡å¤çš„textåˆ—
                if 'text_y' in merged_df.columns:
                    merged_df = merged_df.drop('text_y', axis=1)
                    merged_df = merged_df.rename(columns={'text_x': 'text'})

                logger.info(f"âœ… æ‰€æœ‰èˆ†æƒ…åˆ†æåˆå¹¶å®Œæˆï¼æ€»è®¡ {len(merged_df)} æ¡æ•°æ®")
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(merged_df),
                    'analysis_summary': analysis_summary,
                    'message': "æ‰€æœ‰èˆ†æƒ…åˆ†æç»“æœåˆå¹¶å®Œæˆ",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            except Exception as e:
                error_msg = f"åˆå¹¶åˆ†æç»“æœæ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg)
                raise InternalServerError(error_msg)

            # æ ¹æ®commenter_uniqueIdå»é‡
            analyzed_df = merged_df.drop_duplicates(subset=['commenter_uniqueId'])

            # ç”Ÿæˆåˆ†ææ‘˜è¦
            analysis_summary = {
                'sentiment_distribution': self.analyze_sentiment_distribution(analyzed_df),
                'emotion_patterns': self.analyze_emotion_patterns(analyzed_df),
                'engagement_patterns': self.analyze_engagement_patterns(analyzed_df),
                'themes': self.analyze_themes(analyzed_df),
                'meta': {
                    'total_analyzed_comments': len(analyzed_df),
                    'aweme_id': aweme_id,
                    'analysis_type': 'purchase_intent_stats',
                    'analysis_timestamp': datetime.now().isoformat(),
                }
            }

            # ç”ŸæˆæŠ¥å‘Š
            result = await self.generate_analysis_report(aweme_id, 'sentiment_report', analysis_summary)
            llm_processing_cost['total_cost'] += result['cost']['total_cost']
            llm_processing_cost['input_cost'] += result['cost']['input_cost']
            llm_processing_cost['output_cost'] += result['cost']['output_cost']

            # è¿”å›æœ€ç»ˆç»“æœ
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(analyzed_df),
                'report_url': result['report_url'],
                'analysis_summary': analysis_summary,
                'message': "èˆ†æƒ…åˆ†æå®Œæˆ",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 100, 2)
            }

        except (ValidationError, ExternalAPIError, InternalServerError) as e:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿™äº›å·²å¤„ç†çš„é”™è¯¯
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé¢„æœŸé”™è¯¯: {str(e)}")
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'error': str(e),
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(results) if 'results' in locals() else 0,
                'analysis_summary': analysis_summary,
                'message': f"èˆ†æƒ…åˆ†æå¤±è´¥: {str(e)}",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 100, 2)
            }
            return  # ç¡®ä¿ç”Ÿæˆå™¨åœ¨è¿”å›é”™è¯¯ååœæ­¢

    def analyze_sentiment_distribution(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææƒ…æ„Ÿåˆ†å¸ƒ"""
        sentiment_counts = df['sentiment'].value_counts()
        total_comments = len(df)

        return {
            'distribution': {
                sentiment: {
                    'count': int(count),
                    'percentage': round(count / total_comments * 100, 2)
                }
                for sentiment, count in sentiment_counts.items()
            },
            'dominant_sentiment': sentiment_counts.index[0],
            'sentiment_ratio': {
                'positive_ratio': round(len(df[df['sentiment'] == 'positive']) / total_comments * 100, 2),
                'negative_ratio': round(len(df[df['sentiment'] == 'negative']) / total_comments * 100, 2),
                'neutral_ratio': round(len(df[df['sentiment'] == 'neutral']) / total_comments * 100, 2)
            }
        }

    def analyze_emotion_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææƒ…ç»ªæ¨¡å¼"""
        emotion_counts = df['emotion'].value_counts()
        sentiment_emotion_matrix = pd.crosstab(df['sentiment'], df['emotion'])

        return {
            'dominant_emotions': {
                'overall': emotion_counts.index[0],
                'by_sentiment': {
                    sentiment: sentiment_emotion_matrix.loc[sentiment].idxmax()
                    for sentiment in sentiment_emotion_matrix.index
                }
            },
            'emotion_distribution': {
                emotion: int(count)
                for emotion, count in emotion_counts.items()
            },
            'emotion_sentiment_correlation': {
                sentiment: {
                    emotion: int(count)
                    for emotion, count in row.items()
                }
                for sentiment, row in sentiment_emotion_matrix.iterrows()
            }
        }

    def analyze_engagement_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æäº’åŠ¨æ¨¡å¼"""
        engagement_counts = df['engagement_type'].value_counts()
        engagement_sentiment = pd.crosstab(df['engagement_type'], df['sentiment'])

        return {
            'engagement_distribution': {
                engagement: int(count)
                for engagement, count in engagement_counts.items()
            },
            'engagement_by_sentiment': {
                engagement: {
                    sentiment: int(count)
                    for sentiment, count in row.items()
                }
                for engagement, row in engagement_sentiment.iterrows()
            },
            'key_findings': {
                'most_common_engagement': engagement_counts.index[0],
                'least_common_engagement': engagement_counts.index[-1],
                'positive_engagement_rate': round(
                    engagement_sentiment.loc['supportive', 'positive'] /
                    engagement_sentiment.loc['supportive'].sum() * 100, 2
                )
            }
        }

    def analyze_themes(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå…³é”®ä¸»é¢˜"""
        # å±•å¼€ä¸»é¢˜åˆ—è¡¨
        all_themes = [theme for themes in df['key_themes'] for theme in themes]
        theme_counts = Counter(all_themes)

        # æŒ‰æƒ…æ„Ÿåˆ†ç±»çš„ä¸»é¢˜
        theme_by_sentiment = {
            'positive': [
                theme for i, themes in df[df['sentiment'] == 'positive']['key_themes'].items()
                for theme in themes
            ],
            'negative': [
                theme for i, themes in df[df['sentiment'] == 'negative']['key_themes'].items()
                for theme in themes
            ],
            'neutral': [
                theme for i, themes in df[df['sentiment'] == 'neutral']['key_themes'].items()
                for theme in themes
            ]
        }

        return {
            'overall_themes': {
                theme: count
                for theme, count in theme_counts.most_common()
            },
            'themes_by_sentiment': {
                sentiment: dict(Counter(themes).most_common(5))
                for sentiment, themes in theme_by_sentiment.items()
            },
            'key_insights': {
                'top_themes': list(dict(theme_counts.most_common(5)).keys()),
                'theme_diversity': len(theme_counts),
                'average_themes_per_comment': round(len(all_themes) / len(df), 2)
            }
        }

    """---------------------------------------------å…³ç³»åˆ†æ-----------------------------------------------"""

    async def fetch_relationship_analysis(self, aweme_id: str, batch_size: int = 30, concurrency: int = 5) -> \
    AsyncGenerator[Dict[str, Any], None]:
        """
        åˆ†ææŒ‡å®šè§†é¢‘çš„è¯„è®ºä¸­çš„å…³ç³»å’Œäº’åŠ¨

        Args:
            aweme_id (str): è§†é¢‘ID
            batch_size (int, optional): æ¯æ‰¹å¤„ç†çš„è¯„è®ºæ•°é‡ï¼Œé»˜è®¤30
            concurrency (int, optional): å¹¶å‘å¤„ç†çš„æ‰¹æ¬¡æ•°é‡ï¼Œé»˜è®¤5

        Returns:
            Dict[str, Any]: å…³ç³»åˆ†æç»“æœ

        Raises:
            ValidationError: å½“aweme_idä¸ºç©ºæˆ–æ— æ•ˆæ—¶
            ExternalAPIError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
            InternalServerError: å½“åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
        """

        if not aweme_id:
            raise ValidationError(detail="aweme_idä¸èƒ½ä¸ºç©º", field="aweme_id")

        if batch_size <= 0 or batch_size > settings.MAX_BATCH_SIZE:
            raise ValidationError(
                detail=f"batch_sizeå¿…é¡»åœ¨1å’Œ{settings.MAX_BATCH_SIZE}ä¹‹é—´",
                field="batch_size"
            )

        start_time = time.time()
        comments = []
        results = []
        analysis_summary = {}
        total_collected_comments = 0
        total_analyzed_comments = 0
        llm_processing_cost = {'total_cost': 0.0, 'input_cost': 0.0, 'output_cost': 0.0}

        try:
            # æµå¼è·å–è¯„è®º
            async for comments_batch in self.fetch_video_comments(aweme_id):
                if 'error' not in comments_batch and not comments_batch['is_complete']:
                    comments.append(comments_batch['current_batch_comments'])
                    total_collected_comments += comments_batch['current_batch_count']
                else:
                    comments = comments_batch.get('comments', [])
                    total_collected_comments = comments_batch.get('total_comments', 0)

                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': total_analyzed_comments,
                    'analysis_summary': analysis_summary,
                    'message': f"æ­£åœ¨è·å–è¯„è®º: {total_collected_comments} æ¡",
                    'timestamp': comments_batch.get('timestamp', datetime.now().isoformat()),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # æ•°æ®éªŒè¯
            if len(comments) == 0:
                raise ValidationError(detail="è·å–åˆ°çš„è¯„è®ºæ•°æ®ä¸ºç©º", field="comments")

            comments_df = pd.DataFrame(comments)

            if 'text' not in comments_df.columns:
                raise ValidationError(detail="è¯„è®ºæ•°æ®å¿…é¡»åŒ…å«'text'åˆ—", field="comments")

            # éªŒè¯å’Œè°ƒæ•´æ‰¹å¤„ç†å‚æ•°
            batch_size = min(batch_size, settings.MAX_BATCH_SIZE)
            concurrency = min(concurrency, 10)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º10

            # åˆ†æ‰¹å¤„ç†DataFrame
            num_splits = max(1, len(comments_df) // batch_size + (1 if len(comments_df) % batch_size > 0 else 0))
            comment_batches = np.array_split(comments_df, num_splits)

            # é¿å…ç©ºæ‰¹æ¬¡
            comment_batches = [batch for batch in comment_batches if not batch.empty]

            if not comment_batches:
                raise InternalServerError("åˆ†å‰²åçš„æ‰¹æ¬¡æ•°æ®ä¸ºç©º")

            avg_batch_size = len(comment_batches[0]) if comment_batches else 0

            # é€šçŸ¥å¼€å§‹åˆ†æ
            yield {
                'aweme_id': aweme_id,
                'is_complete': False,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': total_analyzed_comments,
                'analysis_summary': analysis_summary,
                'message': f"å¼€å§‹å…³ç³»åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

            logger.info(
                f"å¼€å§‹å…³ç³»åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º"
            )

            # æ‰¹æ¬¡å¤„ç†
            for i in range(0, len(comment_batches), concurrency):
                batch_group = comment_batches[i:i + concurrency]

                # è®°å½•å½“å‰å¹¶å‘ç»„çš„èŒƒå›´
                batch_indices = [
                    f"{batch.index[0]}-{batch.index[-1]}" for batch in batch_group
                ]
                logger.info(
                    f"âš¡ å¤„ç†æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}"
                )

                # å¹¶å‘æ‰§è¡Œæ‰¹å¤„ç†ä»»åŠ¡
                tasks = [
                    self._analyze_aspect('relationship', batch[['text', 'comment_id']].to_dict('records'))
                    for batch in batch_group
                ]

                batch_results = await asyncio.gather(*tasks, return_exceptions=True)

                # å¤„ç†ç»“æœï¼Œè¿‡æ»¤æ‰å¼‚å¸¸
                error_count = 0

                for j, result in enumerate(batch_results):
                    if isinstance(result, Exception):
                        error_msg = f"æ‰¹æ¬¡ {i + j + 1} åˆ†æå¤±è´¥: {str(result)}"
                        logger.error(error_msg)
                        error_count += 1
                    else:
                        results.extend(result['response'])
                        llm_processing_cost['total_cost'] += result['cost']['total_cost']
                        llm_processing_cost['input_cost'] += result['cost']['input_cost']
                        llm_processing_cost['output_cost'] += result['cost']['output_cost']

                # åªåœ¨æœ‰é”™è¯¯æ—¶æ‰å‘é€é”™è¯¯è¿›åº¦æ›´æ–°
                if error_count > 0:
                    raise InternalServerError(f"æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)} åˆ†æå¤±è´¥")

                # å‘é€è¿›åº¦æ›´æ–°
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(results),
                    'analysis_summary': analysis_summary,
                    'message': f"å·²åˆ†ææ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}ï¼Œç»§ç»­å¤„ç†...",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # åˆå¹¶æ‰€æœ‰åˆ†æç»“æœ
            try:
                # åˆ›å»ºç»“æœDataFrame
                if not results:
                    raise InternalServerError("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœ")
                analysis_df = pd.DataFrame(results)
                merged_df = pd.merge(comments_df, analysis_df, on='comment_id', how='left')

                # å¤„ç†é‡å¤çš„textåˆ—
                if 'text_y' in merged_df.columns:
                    merged_df = merged_df.drop('text_y', axis=1)
                    merged_df = merged_df.rename(columns={'text_x': 'text'})

                logger.info(f"âœ… æ‰€æœ‰å…³ç³»åˆ†æåˆå¹¶å®Œæˆï¼æ€»è®¡ {len(merged_df)} æ¡æ•°æ®")
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(merged_df),
                    'analysis_summary': analysis_summary,
                    'message': "æ‰€æœ‰å…³ç³»åˆ†æç»“æœåˆå¹¶å®Œæˆ",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            except Exception as e:
                error_msg = f"åˆå¹¶åˆ†æç»“æœæ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg)
                raise InternalServerError(error_msg)

            # æ ¹æ®commenter_uniqueIdå»é‡
            analyzed_df = merged_df.drop_duplicates(subset=['commenter_uniqueId'])

            # ç”Ÿæˆåˆ†ææ‘˜è¦
            analysis_summary = {
                'trust_analysis': self.analyze_trust_metrics(analyzed_df),
                'tone_analysis': self.analyze_audience_tone(analyzed_df),
                'fandom_analysis': self.analyze_fandom_composition(analyzed_df),
                'segment_analysis': self.analyze_audience_segments(analyzed_df),
                'fan_list': {
                    'loyal_fans_info': self.extract_fan_group(analyzed_df, 'trust_level', 'loyal_fan', 'loyal_fans'),
                    'superfans_info': self.extract_fan_group(analyzed_df, 'fandom_level', 'superfan', 'superfans'),
                    'new_followers_info': self.extract_fan_group(analyzed_df, 'previous_knowledge', 'new_follower',
                                                                 'new_followers'),
                    'returning_audience_info': self.extract_fan_group(analyzed_df, 'previous_knowledge',
                                                                      'returning_audience', 'returning_audience'),
                    'long_time_fans_info': self.extract_fan_group(analyzed_df, 'previous_knowledge', 'long_time_fan',
                                                                  'long_time_fans'),
                },
                'meta': {
                    'total_analyzed_comments': len(analyzed_df),
                    'aweme_id': aweme_id,
                    'analysis_type': 'relationship',
                    'analysis_timestamp': datetime.now().isoformat(),
                }
            }

            # ç”ŸæˆæŠ¥å‘Š
            result = await self.generate_analysis_report(aweme_id, 'relationship_report', analysis_summary)
            llm_processing_cost['total_cost'] += result['cost']['total_cost']
            llm_processing_cost['input_cost'] += result['cost']['input_cost']
            llm_processing_cost['output_cost'] += result['cost']['output_cost']

            # è¿”å›æœ€ç»ˆç»“æœ
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(analyzed_df),
                'report_url': result['report_url'],
                'analysis_summary': analysis_summary,
                'message': "å…³ç³»åˆ†æå®Œæˆ",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

        except (ValidationError, ExternalAPIError, InternalServerError) as e:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿™äº›å·²å¤„ç†çš„é”™è¯¯
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé¢„æœŸé”™è¯¯: {str(e)}")
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'error': str(e),
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(results) if 'results' in locals() else 0,
                'analysis_summary': analysis_summary,
                'message': f"å…³ç³»åˆ†æå¤±è´¥: {str(e)}",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }
            return  # ç¡®ä¿ç”Ÿæˆå™¨åœ¨è¿”å›é”™è¯¯ååœæ­¢

    def analyze_trust_metrics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå—ä¼—ä¿¡ä»»åº¦æŒ‡æ ‡"""
        trust_counts = df['trust_level'].value_counts()
        total_comments = len(df)

        # è®¡ç®—ä¿¡ä»»åˆ†æ•°
        trust_score = (
                              (len(df[df['trust_level'] == 'loyal_fan']) * 1.0 +
                               len(df[df['trust_level'] == 'indifferent']) * 0.5 +
                               len(df[df['trust_level'] == 'skeptical']) * 0.0) / total_comments
                      ) * 100

        return {
            'trust_distribution': {
                level: {
                    'count': int(count),
                    'percentage': round(count / total_comments * 100, 2)
                }
                for level, count in trust_counts.items()
            },
            'trust_metrics': {
                'overall_trust_score': round(trust_score, 2),
                'loyal_fan_ratio': round(len(df[df['trust_level'] == 'loyal_fan']) / total_comments * 100, 2),
                'skepticism_ratio': round(len(df[df['trust_level'] == 'skeptical']) / total_comments * 100, 2)
            },
            'key_findings': {
                'dominant_trust_level': trust_counts.index[0],
                'trust_trend': 'positive' if trust_score > 60 else 'neutral' if trust_score > 40 else 'concerning'
            }
        }

    def analyze_audience_tone(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå—ä¼—æ€åº¦å€¾å‘"""
        tone_counts = df['tone_toward_influencer'].value_counts()
        tone_by_trust = pd.crosstab(df['tone_toward_influencer'], df['trust_level'])

        return {
            'tone_distribution': {
                tone: {
                    'count': int(count),
                    'percentage': round(count / len(df) * 100, 2)
                }
                for tone, count in tone_counts.items()
            },
            'tone_by_trust_level': {
                tone: {
                    trust_level: int(count)
                    for trust_level, count in row.items()
                }
                for tone, row in tone_by_trust.iterrows()
            },
            'sentiment_metrics': {
                'positivity_ratio': round(
                    len(df[df['tone_toward_influencer'] == 'supportive']) / len(df) * 100, 2),
                'criticism_ratio': round(
                    len(df[df['tone_toward_influencer'] == 'critical']) / len(df) * 100, 2)
            }
        }

    def analyze_fandom_composition(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æç²‰ä¸æ„æˆ"""
        fandom_counts = df['fandom_level'].value_counts()
        knowledge_counts = df['previous_knowledge'].value_counts()

        # ç²‰ä¸å¿ è¯šåº¦çŸ©é˜µ
        loyalty_matrix = pd.crosstab(
            df['fandom_level'],
            df['previous_knowledge']
        )

        return {
            'fandom_distribution': {
                level: {
                    'count': int(count),
                    'percentage': round(count / len(df) * 100, 2)
                }
                for level, count in fandom_counts.items()
            },
            'audience_history': {
                knowledge: {
                    'count': int(count),
                    'percentage': round(count / len(df) * 100, 2)
                }
                for knowledge, count in knowledge_counts.items()
            },
            'loyalty_patterns': {
                fandom: {
                    knowledge: int(count)
                    for knowledge, count in row.items()
                }
                for fandom, row in loyalty_matrix.iterrows()
            },
            'audience_metrics': {
                'superfan_ratio': round(len(df[df['fandom_level'] == 'superfan']) / len(df) * 100, 2),
                'new_audience_ratio': round(
                    len(df[df['previous_knowledge'] == 'new_follower']) / len(df) * 100, 2),
                'retention_indicator': round(
                    len(df[df['previous_knowledge'].isin(['returning_audience', 'long_time_fan'])]) / len(
                        df) * 100, 2)
            }
        }

    def analyze_audience_segments(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æå—ä¼—ç»†åˆ†"""
        # åˆ›å»ºå¤åˆç‰¹å¾
        df['audience_segment'] = df.apply(self._determine_segment, axis=1)
        segment_counts = df['audience_segment'].value_counts()

        return {
            'segment_distribution': {
                segment: {
                    'count': int(count),
                    'percentage': round(count / len(df) * 100, 2)
                }
                for segment, count in segment_counts.items()
            },
            'segment_characteristics': self._analyze_segment_characteristics(df),
            'segment_engagement': self._analyze_segment_engagement(df),
        }

    def _determine_segment(self, row) -> str:
        """ç¡®å®šå—ä¼—æ‰€å±ç»†åˆ†"""
        if row['trust_level'] == 'loyal_fan' and row['fandom_level'] == 'superfan':
            return 'core_community'
        elif row['previous_knowledge'] == 'new_follower':
            return 'new_audience'
        elif row['tone_toward_influencer'] == 'critical':
            return 'critics'
        elif row['engagement_type'] in ['curiosity', 'casual_remark']:
            return 'casual_viewers'
        else:
            return 'regular_audience'

    def _analyze_segment_characteristics(self, df: pd.DataFrame) -> Dict[str, Dict[str, Any]]:
        """åˆ†æå„ç»†åˆ†å—ä¼—çš„ç‰¹å¾"""
        segments = df['audience_segment'].unique()
        characteristics = {}

        for segment in segments:
            segment_df = df[df['audience_segment'] == segment]
            characteristics[segment] = {
                'trust_level': segment_df['trust_level'].mode()[0],
                'typical_engagement': segment_df['engagement_type'].mode()[0],
                'average_fandom_level': segment_df['fandom_level'].mode()[0]
            }

        return characteristics

    def _analyze_segment_engagement(self, df: pd.DataFrame) -> Dict[str, Dict[str, Any]]:
        """åˆ†æå„ç»†åˆ†å—ä¼—çš„äº’åŠ¨æ¨¡å¼"""
        segments = df['audience_segment'].unique()
        engagement_patterns = {}

        for segment in segments:
            segment_df = df[df['audience_segment'] == segment]
            engagement_patterns[segment] = {
                'common_engagement_types': segment_df['engagement_type'].value_counts().to_dict(),
                'engagement_rate': round(len(segment_df) / len(df) * 100, 2)
            }

        return engagement_patterns

    def extract_fan_group(self, df: pd.DataFrame, filter_column: str, filter_value: str, group_name: str) -> Dict[str, Any]:
        """
        æå–ç‰¹å®šç±»å‹çš„ç²‰ä¸ç¾¤ä½“ä¿¡æ¯

        Args:
            df (pd.DataFrame): åŒ…å«ç²‰ä¸æ•°æ®çš„DataFrame
            filter_column (str): ç”¨äºç­›é€‰çš„åˆ—å
            filter_value (str): ç­›é€‰æ¡ä»¶çš„å€¼
            group_name (str): ç²‰ä¸ç¾¤ä½“çš„åç§°

        Returns:
            Dict[str, Any]: åŒ…å«ç²‰ä¸æ€»æ•°å’Œç²‰ä¸è¯¦æƒ…çš„å­—å…¸
        """
        fan_group = df[df[filter_column] == filter_value]
        columns = ['commenter_uniqueId', 'text', 'commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']
        fan_group = fan_group[columns]

        return {
            f'total_{group_name}': len(fan_group),
            f'{group_name}': fan_group.to_dict('records')
        }

    """---------------------------------------------å·®è¯„åˆ†æ-----------------------------------------------"""

    async def fetch_toxicity_analysis(self, aweme_id: str, batch_size: int = 30, concurrency: int = 5) -> \
    AsyncGenerator[Dict[str, Any], None]:
        """
        åˆ†ææŒ‡å®šè§†é¢‘çš„è¯„è®ºæ¯’æ€§/æœ‰å®³æ€§/è¿è§„æ€§

        Args:
            aweme_id (str): è§†é¢‘ID
            batch_size (int, optional): æ¯æ‰¹å¤„ç†çš„è¯„è®ºæ•°é‡ï¼Œé»˜è®¤30
            concurrency (int, optional): å¹¶å‘å¤„ç†çš„æ‰¹æ¬¡æ•°é‡ï¼Œé»˜è®¤5

        Returns:
            Dict[str, Any]: æ¯’æ€§åˆ†æç»“æœ

        Raises:
            ValidationError: å½“aweme_idä¸ºç©ºæˆ–æ— æ•ˆæ—¶
            ExternalAPIError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
            InternalServerError: å½“åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
        """

        if not aweme_id:
            raise ValidationError(detail="aweme_idä¸èƒ½ä¸ºç©º", field="aweme_id")

        if batch_size <= 0 or batch_size > settings.MAX_BATCH_SIZE:
            raise ValidationError(
                detail=f"batch_sizeå¿…é¡»åœ¨1å’Œ{settings.MAX_BATCH_SIZE}ä¹‹é—´",
                field="batch_size"
            )

        start_time = time.time()
        comments = []
        results = []
        analysis_summary = {}
        total_collected_comments = 0
        total_analyzed_comments = 0
        llm_processing_cost = {'total_cost': 0.0, 'input_cost': 0.0, 'output_cost': 0.0}

        try:
            # æµå¼è·å–è¯„è®º
            async for comments_batch in self.fetch_video_comments(aweme_id):
                if 'error' not in comments_batch and not comments_batch['is_complete']:
                    comments.append(comments_batch['current_batch_comments'])
                    total_collected_comments += comments_batch['current_batch_count']
                else:
                    comments = comments_batch.get('comments', [])
                    total_collected_comments = comments_batch.get('total_comments', 0)

                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': total_analyzed_comments,
                    'analysis_summary': analysis_summary,
                    'message': f"æ­£åœ¨è·å–è¯„è®º: {total_collected_comments} æ¡",
                    'timestamp': comments_batch.get('timestamp', datetime.now().isoformat()),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # æ•°æ®éªŒè¯
            if len(comments) == 0:
                raise ValidationError(detail="è·å–åˆ°çš„è¯„è®ºæ•°æ®ä¸ºç©º", field="comments")

            comments_df = pd.DataFrame(comments)

            if 'text' not in comments_df.columns:
                raise ValidationError(detail="è¯„è®ºæ•°æ®å¿…é¡»åŒ…å«'text'åˆ—", field="comments")

            # éªŒè¯å’Œè°ƒæ•´æ‰¹å¤„ç†å‚æ•°
            batch_size = min(batch_size, settings.MAX_BATCH_SIZE)
            concurrency = min(concurrency, 10)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º10

            # åˆ†æ‰¹å¤„ç†DataFrame
            num_splits = max(1, len(comments_df) // batch_size + (1 if len(comments_df) % batch_size > 0 else 0))
            comment_batches = np.array_split(comments_df, num_splits)

            # é¿å…ç©ºæ‰¹æ¬¡
            comment_batches = [batch for batch in comment_batches if not batch.empty]

            if not comment_batches:
                raise InternalServerError("åˆ†å‰²åçš„æ‰¹æ¬¡æ•°æ®ä¸ºç©º")

            avg_batch_size = len(comment_batches[0]) if comment_batches else 0

            # é€šçŸ¥å¼€å§‹åˆ†æ
            yield {
                'aweme_id': aweme_id,
                'is_complete': False,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': total_analyzed_comments,
                'analysis_summary': analysis_summary,
                'message': f"å¼€å§‹æ¯’æ€§åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

            logger.info(
                f"å¼€å§‹æ¯’æ€§åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º"
            )

            # æ‰¹æ¬¡å¤„ç†
            for i in range(0, len(comment_batches), concurrency):
                batch_group = comment_batches[i:i + concurrency]

                # è®°å½•å½“å‰å¹¶å‘ç»„çš„èŒƒå›´
                batch_indices = [
                    f"{batch.index[0]}-{batch.index[-1]}" for batch in batch_group
                ]
                logger.info(
                    f"âš¡ å¤„ç†æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}"
                )

                # å¹¶å‘æ‰§è¡Œæ‰¹å¤„ç†ä»»åŠ¡
                tasks = [
                    self._analyze_aspect('toxicity', batch[['text', 'comment_id']].to_dict('records'))
                    for batch in batch_group
                ]

                batch_results = await asyncio.gather(*tasks, return_exceptions=True)

                # å¤„ç†ç»“æœï¼Œè¿‡æ»¤æ‰å¼‚å¸¸
                error_count = 0

                for j, result in enumerate(batch_results):
                    if isinstance(result, Exception):
                        error_msg = f"æ‰¹æ¬¡ {i + j + 1} åˆ†æå¤±è´¥: {str(result)}"
                        logger.error(error_msg)
                        error_count += 1
                    else:
                        results.extend(result['response'])
                        llm_processing_cost['total_cost'] += result['cost']['total_cost']
                        llm_processing_cost['input_cost'] += result['cost']['input_cost']
                        llm_processing_cost['output_cost'] += result['cost']['output_cost']

                # åªåœ¨æœ‰é”™è¯¯æ—¶æ‰å‘é€é”™è¯¯è¿›åº¦æ›´æ–°
                if error_count > 0:
                    raise InternalServerError(f"æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)} åˆ†æå¤±è´¥")

                # å‘é€è¿›åº¦æ›´æ–°
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(results),
                    'analysis_summary': analysis_summary,
                    'message': f"å·²åˆ†ææ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}ï¼Œç»§ç»­å¤„ç†...",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # åˆå¹¶æ‰€æœ‰åˆ†æç»“æœ
            try:
                # åˆ›å»ºç»“æœDataFrame
                if not results:
                    raise InternalServerError("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœ")
                analysis_df = pd.DataFrame(results)
                merged_df = pd.merge(comments_df, analysis_df, on='comment_id', how='left')

                # å¤„ç†é‡å¤çš„textåˆ—
                if 'text_y' in merged_df.columns:
                    merged_df = merged_df.drop('text_y', axis=1)
                    merged_df = merged_df.rename(columns={'text_x': 'text'})

                logger.info(f"âœ… æ‰€æœ‰æ¯’æ€§åˆ†æåˆå¹¶å®Œæˆï¼æ€»è®¡ {len(merged_df)} æ¡æ•°æ®")
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(merged_df),
                    'analysis_summary': analysis_summary,
                    'message': "æ‰€æœ‰æ¯’æ€§åˆ†æç»“æœåˆå¹¶å®Œæˆ",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            except Exception as e:
                error_msg = f"åˆå¹¶åˆ†æç»“æœæ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg)
                raise InternalServerError(error_msg)

            # æå–æœ‰å®³è¯„è®º
            harmful_comments = self._track_harmful_comments(merged_df)

            # ç”Ÿæˆåˆ†ææ‘˜è¦
            analysis_summary = {
                'overview': self._analyze_toxicity_overview(harmful_comments, merged_df),
                'types': self._analyze_toxicity_types(merged_df),
                'severity': self._analyze_severity_levels(merged_df),
                'violations': self._analyze_guideline_violations(merged_df),
                'extreme_harmful_comments': harmful_comments,
                'meta': {
                    'total_analyzed_comments': len(merged_df),
                    'aweme_id': aweme_id,
                    'analysis_type': 'toxicity',
                    'analysis_timestamp': datetime.now().isoformat(),
                }
            }

            # ç”ŸæˆæŠ¥å‘Š
            result = await self.generate_analysis_report(aweme_id, 'toxicity_report', analysis_summary)
            llm_processing_cost['total_cost'] += result['cost']['total_cost']
            llm_processing_cost['input_cost'] += result['cost']['input_cost']
            llm_processing_cost['output_cost'] += result['cost']['output_cost']

            # è¿”å›æœ€ç»ˆç»“æœ
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(merged_df),
                'report_url': result['report_url'],
                'analysis_summary': analysis_summary,
                'message': "æ¯’æ€§åˆ†æå®Œæˆ",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

        except (ValidationError, ExternalAPIError, InternalServerError) as e:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿™äº›å·²å¤„ç†çš„é”™è¯¯
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé¢„æœŸé”™è¯¯: {str(e)}")
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'error': str(e),
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(results) if 'results' in locals() else 0,
                'analysis_summary': analysis_summary,
                'message': f"æ¯’æ€§åˆ†æå¤±è´¥: {str(e)}",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }
            return  # ç¡®ä¿ç”Ÿæˆå™¨åœ¨è¿”å›é”™è¯¯ååœæ­¢

    def _track_harmful_comments(self,df: pd.DataFrame):
        """Track comments that need attention"""
        # æŠŠseverity scoreè½¬æˆint
        df['severity_score'] = df['severity_score'].astype(int)
        harmful_mask = (
                (df['toxicity_level'] == 'high') |
                (df['report_worthiness'] == 'should_report') |
                ((df['severity_score'] >= 7) & (df['community_guidelines_violation'] == True))
        )

        harmful_comments = df[harmful_mask]

        harmful_comments = [
            {
                'comment_id': row['comment_id'],
                'text': row['text'],
                'toxicity_type': row['toxicity_type'],
                'severity_score': row['severity_score'],
                'needs_action': row['report_worthiness'] == 'should_report'
            }
            for _, row in harmful_comments.iterrows()
        ]
        return harmful_comments

    def _analyze_toxicity_overview(self,harmful_comments, df: pd.DataFrame) -> Dict[str, Any]:
        """Generate overview of toxicity levels"""
        total = len(df)

        return {
            'toxicity_levels': {
                level: {
                    'count': int(count),
                    'percentage': round((count / total) * 100, 2)
                }
                for level, count in df['toxicity_level'].value_counts().items()
            },
            'total_harmful_comments': len(harmful_comments),
            'requires_moderation': len(df[df['report_worthiness'] == 'should_report']),
            'guidelines_violations': int(df['community_guidelines_violation'].sum())
        }

    def _analyze_toxicity_types(self,df: pd.DataFrame) -> Dict[str, Any]:
        """Analyze different types of toxic content"""
        type_counts = df['toxicity_type'].value_counts()

        return {
            'distribution': {
                ttype: int(count)
                for ttype, count in type_counts.items()
            },
            'most_common_type': type_counts.index[0],
            'hate_speech_count': int(type_counts.get('hate_speech', 0)),
            'harassment_count': int(type_counts.get('harassment', 0))
        }

    def _analyze_severity_levels(self,df: pd.DataFrame) -> Dict[str, Any]:
        """Analyze severity scores of toxic content"""
        severity_scores = df['severity_score']

        return {
            'average_severity': round(float(severity_scores.mean()), 2),
            'high_severity_count': int(len(df[df['severity_score'] >= 7])),
            'severity_distribution': {
                'low': int(len(severity_scores[severity_scores <= 3])),
                'medium': int(len(severity_scores[(severity_scores > 3) & (severity_scores < 7)])),
                'high': int(len(severity_scores[severity_scores >= 7]))
            }
        }

    def _analyze_guideline_violations(self,df: pd.DataFrame) -> Dict[str, Any]:
        """Analyze community guidelines violations"""
        violations = df[df['community_guidelines_violation'] == True]

        return {
            'total_violations': len(violations),
            'violation_rate': round(len(violations) / len(df) * 100, 2),
            'violations_by_type': violations['toxicity_type'].value_counts().to_dict()
        }

    async def fetch_negative_shop_reviews(self, aweme_id: str, batch_size: int = 30, concurrency: int = 5) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è·å–æŒ‡å®šè§†é¢‘çš„è´Ÿé¢å•†åº—è¯„è®º

        Args:
            aweme_id (str): è§†é¢‘ID
            batch_size (int, optional): æ¯æ‰¹å¤„ç†çš„è¯„è®ºæ•°é‡ï¼Œé»˜è®¤30
            concurrency (int, optional): å¹¶å‘å¤„ç†çš„æ‰¹æ¬¡æ•°é‡ï¼Œé»˜è®¤5

        Returns:
            Dict[str, Any]: åŒ…å«è´Ÿé¢å•†åº—è¯„è®ºçš„æ•°æ®

        Raises:
            ValidationError: å½“aweme_idä¸ºç©ºæˆ–æ— æ•ˆæ—¶
            ExternalAPIError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
            InternalServerError: å½“åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
        """
        if not aweme_id:
            raise ValidationError(detail="aweme_idä¸èƒ½ä¸ºç©º", field="aweme_id")

        if batch_size <= 0 or batch_size > settings.MAX_BATCH_SIZE:
            raise ValidationError(
                detail=f"batch_sizeå¿…é¡»åœ¨1å’Œ{settings.MAX_BATCH_SIZE}ä¹‹é—´",
                field="batch_size"
            )

        start_time = time.time()
        comments = []
        results = []
        negative_shop_reviews = []
        total_collected_comments = 0
        total_analyzed_comments = 0
        llm_processing_cost = {'total_cost': 0.0, 'input_cost': 0.0, 'output_cost': 0.0}

        try:
            # æµå¼è·å–è¯„è®º
            async for comments_batch in self.fetch_video_comments(aweme_id):
                if 'error' not in comments_batch and not comments_batch['is_complete']:
                    comments.append(comments_batch['current_batch_comments'])
                    total_collected_comments += comments_batch['current_batch_count']
                else:
                    comments = comments_batch.get('comments', [])
                    total_collected_comments = comments_batch.get('total_comments', 0)

                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': total_analyzed_comments,
                    'negative_shop_reviews': negative_shop_reviews,
                    'message': f"æ­£åœ¨è·å–è¯„è®º: {total_collected_comments} æ¡",
                    'timestamp': comments_batch.get('timestamp', datetime.now().isoformat()),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # æ•°æ®éªŒè¯
            if len(comments) == 0:
                raise ValidationError(detail="è·å–åˆ°çš„è¯„è®ºæ•°æ®ä¸ºç©º", field="comments")

            comments_df = pd.DataFrame(comments)

            if 'text' not in comments_df.columns:
                raise ValidationError(detail="è¯„è®ºæ•°æ®å¿…é¡»åŒ…å«'text'åˆ—", field="comments")

            # éªŒè¯å’Œè°ƒæ•´æ‰¹å¤„ç†å‚æ•°
            batch_size = min(batch_size, settings.MAX_BATCH_SIZE)
            concurrency = min(concurrency, 10)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º10

            # åˆ†æ‰¹å¤„ç†DataFrame
            num_splits = max(1, len(comments_df) // batch_size + (1 if len(comments_df) % batch_size > 0 else 0))
            comment_batches = np.array_split(comments_df, num_splits)

            # é¿å…ç©ºæ‰¹æ¬¡
            comment_batches = [batch for batch in comment_batches if not batch.empty]

            if not comment_batches:
                raise InternalServerError("åˆ†å‰²åçš„æ‰¹æ¬¡æ•°æ®ä¸ºç©º")

            avg_batch_size = len(comment_batches[0]) if comment_batches else 0

            # é€šçŸ¥å¼€å§‹åˆ†æ
            yield {
                'aweme_id': aweme_id,
                'is_complete': False,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': total_analyzed_comments,
                'negative_shop_reviews': negative_shop_reviews,
                'message': f"å¼€å§‹åº—é“ºå·®è¯„åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

            logger.info(
                f"å¼€å§‹åº—é“ºå·®è¯„åˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º"
            )

            # æ‰¹æ¬¡å¤„ç†
            for i in range(0, len(comment_batches), concurrency):
                batch_group = comment_batches[i:i + concurrency]

                # è®°å½•å½“å‰å¹¶å‘ç»„çš„èŒƒå›´
                batch_indices = [
                    f"{batch.index[0]}-{batch.index[-1]}" for batch in batch_group
                ]
                logger.info(
                    f"âš¡ å¤„ç†æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}"
                )

                # å¹¶å‘æ‰§è¡Œæ‰¹å¤„ç†ä»»åŠ¡
                tasks = [
                    self._analyze_aspect('toxicity', batch[['text', 'comment_id']].to_dict('records'))
                    for batch in batch_group
                ]

                batch_results = await asyncio.gather(*tasks, return_exceptions=True)

                # å¤„ç†ç»“æœï¼Œè¿‡æ»¤æ‰å¼‚å¸¸
                error_count = 0

                for j, result in enumerate(batch_results):
                    if isinstance(result, Exception):
                        error_msg = f"æ‰¹æ¬¡ {i + j + 1} åˆ†æå¤±è´¥: {str(result)}"
                        logger.error(error_msg)
                        error_count += 1
                    else:
                        results.extend(result['response'])
                        llm_processing_cost['total_cost'] += result['cost']['total_cost']
                        llm_processing_cost['input_cost'] += result['cost']['input_cost']
                        llm_processing_cost['output_cost'] += result['cost']['output_cost']

                # åªåœ¨æœ‰é”™è¯¯æ—¶æ‰å‘é€é”™è¯¯è¿›åº¦æ›´æ–°
                if error_count > 0:
                    raise InternalServerError(f"æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)} åˆ†æå¤±è´¥")

                # å‘é€è¿›åº¦æ›´æ–°
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(results),
                    'negative_shop_reviews': negative_shop_reviews,
                    'message': f"å·²åˆ†ææ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}ï¼Œç»§ç»­å¤„ç†...",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # åˆå¹¶æ‰€æœ‰åˆ†æç»“æœ
            try:
                # åˆ›å»ºç»“æœDataFrame
                if not results:
                    raise InternalServerError("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœ")
                analysis_df = pd.DataFrame(results)
                merged_df = pd.merge(comments_df, analysis_df, on='comment_id', how='left')

                # å¤„ç†é‡å¤çš„textåˆ—
                if 'text_y' in merged_df.columns:
                    merged_df = merged_df.drop('text_y', axis=1)
                    merged_df = merged_df.rename(columns={'text_x': 'text'})

                logger.info(f"âœ… æ‰€æœ‰åº—é“ºå·®è¯„åˆ†æåˆå¹¶å®Œæˆï¼æ€»è®¡ {len(merged_df)} æ¡æ•°æ®")
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(merged_df),
                    'negative_shop_reviews': negative_shop_reviews,
                    'message': "æ‰€æœ‰åº—é“ºå·®è¯„åˆ†æç»“æœåˆå¹¶å®Œæˆ",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            except Exception as e:
                error_msg = f"åˆå¹¶åˆ†æç»“æœæ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg)
                raise InternalServerError(error_msg)

            # è·å–è´Ÿé¢å•†åº—è¯„è®º
            negative_shop_reviews = self._get_negative_shop_reviews(merged_df)

            # è¿”å›æœ€ç»ˆç»“æœ
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(merged_df),
                'negative_shop_reviews': negative_shop_reviews,
                'meta': {
                    'total_analyzed_comments': len(merged_df),
                    'aweme_id': aweme_id,
                    'analysis_type': 'toxicity',
                    'analysis_timestamp': datetime.now().isoformat(),
                },
                'message': "åº—é“ºå·®è¯„åˆ†æå®Œæˆ",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

        except (ValidationError, ExternalAPIError, InternalServerError) as e:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿™äº›å·²å¤„ç†çš„é”™è¯¯
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé¢„æœŸé”™è¯¯: {str(e)}")
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'error': str(e),
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(results) if 'results' in locals() else 0,
                'negative_shop_reviews': negative_shop_reviews,
                'message': f"åº—é“ºå·®è¯„åˆ†æå¤±è´¥: {str(e)}",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }
            return  # ç¡®ä¿ç”Ÿæˆå™¨åœ¨è¿”å›é”™è¯¯ååœæ­¢

    async def fetch_hate_spam_speech(self, aweme_id: str, batch_size: int = 30, concurrency: int = 5) -> AsyncGenerator[Dict[str, Any], None]:
        """
        è·å–æŒ‡å®šè§†é¢‘çš„ä»‡æ¨å’Œæ”»å‡»æ€§è¯„è®º

        Args:
            aweme_id (str): è§†é¢‘ID
            batch_size (int, optional): æ¯æ‰¹å¤„ç†çš„è¯„è®ºæ•°é‡ï¼Œé»˜è®¤30
            concurrency (int, optional): å¹¶å‘å¤„ç†çš„æ‰¹æ¬¡æ•°é‡ï¼Œé»˜è®¤5

        Returns:
            Dict[str, Any]: åŒ…å«ä»‡æ¨è¨€è®ºçš„æ•°æ®

        Raises:
            ValidationError: å½“aweme_idä¸ºç©ºæˆ–æ— æ•ˆæ—¶
            ExternalAPIError: å½“ç½‘ç»œè¿æ¥å¤±è´¥æ—¶
            InternalServerError: å½“åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶
        """
        if not aweme_id:
            raise ValidationError(detail="aweme_idä¸èƒ½ä¸ºç©º", field="aweme_id")

        if batch_size <= 0 or batch_size > settings.MAX_BATCH_SIZE:
            raise ValidationError(
                detail=f"batch_sizeå¿…é¡»åœ¨1å’Œ{settings.MAX_BATCH_SIZE}ä¹‹é—´",
                field="batch_size"
            )

        start_time = time.time()
        comments = []
        results = []
        hate_comments = []
        total_collected_comments = 0
        total_analyzed_comments = 0
        llm_processing_cost = {'total_cost': 0.0, 'input_cost': 0.0, 'output_cost': 0.0}

        try:
            # æµå¼è·å–è¯„è®º
            async for comments_batch in self.fetch_video_comments(aweme_id):
                if 'error' not in comments_batch and not comments_batch['is_complete']:
                    comments.append(comments_batch['current_batch_comments'])
                    total_collected_comments += comments_batch['current_batch_count']
                else:
                    comments = comments_batch.get('comments', [])
                    total_collected_comments = comments_batch.get('total_comments', 0)

                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': total_analyzed_comments,
                    'hate_comments': hate_comments,
                    'message': f"æ­£åœ¨è·å–è¯„è®º: {total_collected_comments} æ¡",
                    'timestamp': comments_batch.get('timestamp', datetime.now().isoformat()),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # æ•°æ®éªŒè¯
            if len(comments) == 0:
                raise ValidationError(detail="è·å–åˆ°çš„è¯„è®ºæ•°æ®ä¸ºç©º", field="comments")

            comments_df = pd.DataFrame(comments)

            if 'text' not in comments_df.columns:
                raise ValidationError(detail="è¯„è®ºæ•°æ®å¿…é¡»åŒ…å«'text'åˆ—", field="comments")

            # éªŒè¯å’Œè°ƒæ•´æ‰¹å¤„ç†å‚æ•°
            batch_size = min(batch_size, settings.MAX_BATCH_SIZE)
            concurrency = min(concurrency, 10)  # é™åˆ¶æœ€å¤§å¹¶å‘æ•°ä¸º10

            # åˆ†æ‰¹å¤„ç†DataFrame
            num_splits = max(1, len(comments_df) // batch_size + (1 if len(comments_df) % batch_size > 0 else 0))
            comment_batches = np.array_split(comments_df, num_splits)

            # é¿å…ç©ºæ‰¹æ¬¡
            comment_batches = [batch for batch in comment_batches if not batch.empty]

            if not comment_batches:
                raise InternalServerError("åˆ†å‰²åçš„æ‰¹æ¬¡æ•°æ®ä¸ºç©º")

            avg_batch_size = len(comment_batches[0]) if comment_batches else 0

            # é€šçŸ¥å¼€å§‹åˆ†æ
            yield {
                'aweme_id': aweme_id,
                'is_complete': False,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': total_analyzed_comments,
                'hate_comments': hate_comments,
                'message': f"å¼€å§‹æ¶æ„è¨€è®ºåˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

            logger.info(
                f"å¼€å§‹æ¶æ„è¨€è®ºåˆ†æï¼Œå…± {len(comment_batches)} æ‰¹ï¼Œæ¯æ‰¹çº¦ {avg_batch_size} æ¡è¯„è®º"
            )

            # æ‰¹æ¬¡å¤„ç†
            for i in range(0, len(comment_batches), concurrency):
                batch_group = comment_batches[i:i + concurrency]

                # è®°å½•å½“å‰å¹¶å‘ç»„çš„èŒƒå›´
                batch_indices = [
                    f"{batch.index[0]}-{batch.index[-1]}" for batch in batch_group
                ]
                logger.info(
                    f"âš¡ å¤„ç†æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}"
                )

                # å¹¶å‘æ‰§è¡Œæ‰¹å¤„ç†ä»»åŠ¡
                tasks = [
                    self._analyze_aspect('toxicity', batch[['text', 'comment_id']].to_dict('records'))
                    for batch in batch_group
                ]

                batch_results = await asyncio.gather(*tasks, return_exceptions=True)

                # å¤„ç†ç»“æœï¼Œè¿‡æ»¤æ‰å¼‚å¸¸
                error_count = 0

                for j, result in enumerate(batch_results):
                    if isinstance(result, Exception):
                        error_msg = f"æ‰¹æ¬¡ {i + j + 1} åˆ†æå¤±è´¥: {str(result)}"
                        logger.error(error_msg)
                        error_count += 1
                    else:
                        results.extend(result['response'])
                        llm_processing_cost['total_cost'] += result['cost']['total_cost']
                        llm_processing_cost['input_cost'] += result['cost']['input_cost']
                        llm_processing_cost['output_cost'] += result['cost']['output_cost']

                # åªåœ¨æœ‰é”™è¯¯æ—¶æ‰å‘é€é”™è¯¯è¿›åº¦æ›´æ–°
                if error_count > 0:
                    raise InternalServerError(f"æ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)} åˆ†æå¤±è´¥")

                # å‘é€è¿›åº¦æ›´æ–°
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(results),
                    'hate_comments': hate_comments,
                    'message': f"å·²åˆ†ææ‰¹æ¬¡ {i + 1} è‡³ {i + len(batch_group)}ï¼Œè¯„è®ºç´¢å¼•èŒƒå›´: {batch_indices}ï¼Œç»§ç»­å¤„ç†...",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            # åˆå¹¶æ‰€æœ‰åˆ†æç»“æœ
            try:
                # åˆ›å»ºç»“æœDataFrame
                if not results:
                    raise InternalServerError("æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç»“æœ")
                analysis_df = pd.DataFrame(results)
                merged_df = pd.merge(comments_df, analysis_df, on='comment_id', how='left')

                # å¤„ç†é‡å¤çš„textåˆ—
                if 'text_y' in merged_df.columns:
                    merged_df = merged_df.drop('text_y', axis=1)
                    merged_df = merged_df.rename(columns={'text_x': 'text'})

                logger.info(f"âœ… æ‰€æœ‰æ¶æ„è¨€è®ºåˆ†æåˆå¹¶å®Œæˆï¼æ€»è®¡ {len(merged_df)} æ¡æ•°æ®")
                yield {
                    'aweme_id': aweme_id,
                    'is_complete': False,
                    'llm_processing_cost': llm_processing_cost,
                    'total_collected_comments': total_collected_comments,
                    'total_analyzed_comments': len(merged_df),
                    'hate_comments': hate_comments,
                    'message': "æ‰€æœ‰æ¶æ„è¨€è®ºåˆ†æç»“æœåˆå¹¶å®Œæˆ",
                    'timestamp': datetime.now().isoformat(),
                    'processing_time_ms': round((time.time() - start_time) * 1000, 2)
                }

            except Exception as e:
                error_msg = f"åˆå¹¶åˆ†æç»“æœæ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg)
                raise InternalServerError(error_msg)

            # è·å–ä»‡æ¨è¯„è®º
            hate_comments = self._get_hate_comments(merged_df)
            spam_comments = self._get_scam_comments(merged_df)

            # è¿”å›æœ€ç»ˆç»“æœ
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(merged_df),
                'hate_comments': hate_comments,
                'spam_comments': spam_comments,
                'meta': {
                    'total_analyzed_comments': len(merged_df),
                    'aweme_id': aweme_id,
                    'analysis_type': 'hate_speech',
                    'analysis_timestamp': datetime.now().isoformat(),
                },
                'message': "æ¶æ„è¨€è®ºåˆ†æå®Œæˆ",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }

        except (ValidationError, ExternalAPIError, InternalServerError) as e:
            # ç›´æ¥å‘ä¸Šä¼ é€’è¿™äº›å·²å¤„ç†çš„é”™è¯¯
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé¢„æœŸé”™è¯¯: {str(e)}")
            yield {
                'aweme_id': aweme_id,
                'is_complete': True,
                'error': str(e),
                'llm_processing_cost': llm_processing_cost,
                'total_collected_comments': total_collected_comments,
                'total_analyzed_comments': len(results) if 'results' in locals() else 0,
                'hate_comments': hate_comments,
                'message': f"æ¶æ„è¨€è®ºåˆ†æå¤±è´¥: {str(e)}",
                'timestamp': datetime.now().isoformat(),
                'processing_time_ms': round((time.time() - start_time) * 1000, 2)
            }
            return  # ç¡®ä¿ç”Ÿæˆå™¨åœ¨è¿”å›é”™è¯¯ååœæ­¢

    def _get_negative_shop_reviews(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è·å–è´Ÿé¢å•†åº—è¯„è®º

        Args:
            df (pd.DataFrame): åŒ…å«è¯„è®ºæ•°æ®çš„DataFrame

        Returns:
            Dict[str, Any]: åŒ…å«å„ç±»å‹è´Ÿé¢å•†åº—è¯„è®ºçš„æ•°æ®
        """
        negative_product_reviews = df[df['toxicity_type'] == 'negative_product_review'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]
        negative_shop_reviews = df[df['toxicity_type'] == 'negative_shop_review'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]
        negative_service_reviews = df[df['toxicity_type'] == 'negative_service_review'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]
        return {
            'negative_product_reviews':{
                'total_counts': len(negative_product_reviews),
                'user_info': negative_product_reviews.to_dict('records')
            },
            'negative_shop_reviews':{
                'total_counts': len(negative_shop_reviews),
                'user_info': negative_shop_reviews.to_dict('records')
            },
            'negative_service_reviews':{
                'total_counts': len(negative_service_reviews),
                'user_info': negative_service_reviews.to_dict('records')
            }
        }

    def _get_hate_comments(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è·å–ä»‡æ¨å’Œæ”»å‡»æ€§è¯„è®º

        Args:
            df (pd.DataFrame): åŒ…å«è¯„è®ºæ•°æ®çš„DataFrame

        Returns:
            Dict[str, Any]: åŒ…å«å„ç±»å‹ä»‡æ¨è¯„è®ºçš„æ•°æ®
        """
        hate_speech_comments = df[df['toxicity_type'] == 'hate_speech'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]
        personal_attack_comments = df[df['toxicity_type'] == 'personal_attack'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]
        trolling_comments = df[df['toxicity_type'] == 'trolling'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]

        return {
            'hate_speech_comments':{
                'total_counts': len(hate_speech_comments),
                'user_info': hate_speech_comments.to_dict('records')
            },
            'personal_attack_comments':{
                'total_counts': len(personal_attack_comments),
                'user_info': personal_attack_comments.to_dict('records')
            },
            'trolling_comments':{
                'total_counts': len(trolling_comments),
                'user_info': trolling_comments.to_dict('records')
            }
        }

    def _get_scam_comments(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        è·å–åƒåœ¾å’Œæ¬ºè¯ˆæ€§è¯„è®º

        Args:
            df (pd.DataFrame): åŒ…å«è¯„è®ºæ•°æ®çš„DataFrame

        Returns:
            Dict[str, Any]: åŒ…å«å„ç±»å‹åƒåœ¾è¯„è®ºçš„æ•°æ®
        """

        misinfo_comments = df[df['toxicity_type'] == 'misinformation'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]
        spam_comments = df[df['toxicity_type'] == 'spam'][['commenter_uniqueId', 'text','commenter_secuid', 'ins_id', 'twitter_id', 'commenter_region']]
        return {
            'misInfo_comments':{
                'total_counts': len(misinfo_comments),
                'user_info': misinfo_comments.to_dict('records')
            },
            'spam_comments':{
                'total_counts': len(spam_comments),
                'user_info': spam_comments.to_dict('records')
            }
        }


async def main():
    # åˆ›å»ºä»£ç†
    agent = SentimentAgent()

    # åˆ†æè§†é¢‘è¯„è®ºæƒ…æ„Ÿ
    aweme_id = "123456789"
    sentiment_analysis = await agent.analyze_sentiment(aweme_id)
    print(sentiment_analysis)


if __name__ == "__main__":
    asyncio.run(main())
